{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_aB82fSvdYKB"
      },
      "source": [
        "# LLM - Detect AI Generated Text\n",
        "## Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7itjdvI9dYKD",
        "outputId": "af42ede1-292a-43ea-8e85-bdb1a11a3d73"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from nltk.tokenize import word_tokenize,sent_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from gensim.corpora import Dictionary\n",
        "from gensim.models import word2vec\n",
        "from gensim.models import doc2vec\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.utils import resample\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import auc\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "import keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4LBr4vwNdYKE"
      },
      "outputs": [],
      "source": [
        "initial_dataset = pd.read_csv(\"../../data/train_essays.csv\")\n",
        "prompts_dataset = pd.read_csv(\"../../data/train_prompts.csv\")\n",
        "new_data = pd.read_csv(\"../../data/new_essays_V1.csv\")\n",
        "test_dataset = pd.read_csv(\"../data/test_essays.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZA-apgXdYKF"
      },
      "source": [
        "## Data analisis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "dG45LDWZdYKF",
        "outputId": "79d8fa5c-2d89-4075-ff59-2012af444706"
      },
      "outputs": [],
      "source": [
        "initial_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A5Ufk5XndYKG",
        "outputId": "3450810c-2adc-4c00-fc1f-c2d1456b9634"
      },
      "outputs": [],
      "source": [
        "initial_dataset.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y5ClvnTtdYKH",
        "outputId": "196e4691-b015-4bb9-af88-4c546b343f5e"
      },
      "outputs": [],
      "source": [
        "initial_dataset.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "M6w38AusdYKH",
        "outputId": "b1fdc793-13a5-4d99-d115-2f2e700905a3"
      },
      "outputs": [],
      "source": [
        "initial_dataset.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNIWdXOudYKJ"
      },
      "source": [
        "`generated` - Whether the essay was written by a student (0) or generated by an LLM (1). This field is the target and is not present in test_essays.csv."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "opIz_MYjdYKK",
        "outputId": "a0779745-675b-420c-ab35-9f76ed996bd4"
      },
      "outputs": [],
      "source": [
        "initial_dataset.value_counts(\"generated\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dR2Ut5ModYKK",
        "outputId": "7116634c-ea81-4443-d71c-ec79f3823973"
      },
      "outputs": [],
      "source": [
        "generated = initial_dataset.value_counts(\"generated\")\n",
        "generated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F2vi4-PUdYKL",
        "outputId": "8462130b-38f0-4589-853a-ac85d77928d1"
      },
      "outputs": [],
      "source": [
        "generated = generated.apply(lambda x : x/initial_dataset.shape[0])\n",
        "generated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "T-caBmNmdYKL",
        "outputId": "0e2f175e-45cc-45ad-be23-6aa097778e24"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(4,3))\n",
        "fig.suptitle(\"Generated\")\n",
        "ax.bar(\n",
        "    x=[\"By studentes\",\"By LLM\"],\n",
        "    height=generated,\n",
        "    width=0.2,\n",
        "    color=[\"red\",\"green\"],\n",
        "    align=\"center\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "cEvFa1lQdYKL",
        "outputId": "cda624f9-81ba-42a5-eb31-d723b1f7ac01"
      },
      "outputs": [],
      "source": [
        "prompts_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJArVOlmdYKL",
        "outputId": "5db7ce67-19ba-45b9-9925-b71fe40f2819"
      },
      "outputs": [],
      "source": [
        "prompts = initial_dataset.value_counts(\"prompt_id\")\n",
        "prompts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "O-fg234YdYKM",
        "outputId": "3a4c4755-4c18-4789-c7ed-b079cfffd362"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(4,3))\n",
        "fig.suptitle(\"Prompts\")\n",
        "ax.bar(\n",
        "    x=[\"Car-free cities\",\"Does the electoral college work?\"],\n",
        "    height=prompts,\n",
        "    width=0.2,\n",
        "    color=[\"red\",\"green\"],\n",
        "    align=\"center\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(initial_dataset.shape)\n",
        "initial_dataset.drop_duplicates(subset=[\"text\"],inplace=True)\n",
        "initial_dataset.reset_index(drop=True, inplace=True)\n",
        "print(initial_dataset.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yHzxLez5dYKM"
      },
      "source": [
        "## Handle imbalanced Data\n",
        "\n",
        "> Because the class distribution is not balanced, most machine learning algorithms will perform\n",
        "poorly and require modification to avoid simply predicting the majority class in all cases.\n",
        "Additionally, metrics like classification accuracy lose their meaning and alternate methods for\n",
        "evaluating predictions on imbalanced examples are required, like ROC area under curve. This is\n",
        "the foundational challenge of imbalanced classification.\n",
        ">\n",
        "> - Jason Brownlee, *Imbalanced Classification with Python* (2020)\n",
        "\n",
        "> If we think about feature space spatially, we might like all examples in one class to be located on one part\n",
        "of the space, and those from the other class to appear in another part of the space. [...]\n",
        ">This is rarely the case, and it is more likely that each class has multiple **concepts** resulting in multiple different groups or clusters of examples in feature space.\n",
        ">\n",
        "> - Jason Brownlee, *Imbalanced Classification with Python* (2020)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-53GminWdYKM"
      },
      "source": [
        "### Metrics for Imbalanced Data\n",
        "\n",
        ">Although widely used, classification accuracy is almost universally inappropriate for imbalanced classification. The reason is, a high accuracy (or low error) is achievable by a no skill model that only predicts the majority class. [...]\n",
        ">\n",
        "> - Jason Brownlee, *Imbalanced Classification with Python* (2020)\n",
        "\n",
        ">There are two groups of metrics that may be useful for imbalanced classification because they focus on one class; they are sensitivity-specificity and precision-recall.\n",
        ">\n",
        "> - Jason Brownlee, *Imbalanced Classification with Python* (2020)\n",
        "\n",
        ">One limitation of these metrics is that they assume that the class distribution observed in the training dataset will match the distribution in the test set and in real data when the model is used to make predictions. [...] Ranking metrics donâ€™t make any assumptions about class distributions.\n",
        ">\n",
        "> - Jason Brownlee, *Imbalanced Classification with Python* (2020)\n",
        "\n",
        ">The most commonly used ranking metric is the ROC Curve or ROC Analysis. ROC is an\n",
        "acronym that means Receiver Operating Characteristic and summarizes a field of study for\n",
        "analyzing binary classifiers based on their ability to discriminate classes.\n",
        ">\n",
        "> - Jason Brownlee, *Imbalanced Classification with Python* (2020)\n",
        "\n",
        ">Although generally effective, the ROC Curve and ROC AUC can be optimistic under a severe class imbalance, especially when the number of examples in the minority class is small.\n",
        "An alternative to the ROC Curve is the precision-recall curve that can be used in a similar way, although focuses on the performance of the classifier on the minority class.\n",
        ">\n",
        "> - Jason Brownlee, *Imbalanced Classification with Python* (2020)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5EjLehn3dYKN"
      },
      "source": [
        "#### ROC AUC curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FvEDVQHVdYKN"
      },
      "outputs": [],
      "source": [
        "def ROCplot(model,x_val,y_val):\n",
        "    #define metrics\n",
        "    y_pred = model.predict(x_val).ravel()\n",
        "    fpr, tpr, _ = roc_curve(y_val,  y_pred)\n",
        "    aucVal = auc(fpr, tpr)\n",
        "    #create ROC curve\n",
        "    plt.plot(fpr,tpr,label=\"AUC=\"+str(aucVal))\n",
        "    plt.plot([0, 1], [0, 1], color='gray', lw=1, linestyle='--', label='AUC = 0.50')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Rqz4YundYKN"
      },
      "source": [
        "### Data Sampling for imbalanced data\n",
        "\n",
        "> Sadly, k-fold cross-validation is not appropriate for evaluating imbalanced classifiers.\n",
        "[...]\n",
        "The reason is that the data is split into k-folds with a uniform probability distribution. This might work fine for data with a balanced class distribution, but when the distribution is severely skewed, it is likely that one or more folds will have few or no examples from the minority class.\n",
        ">\n",
        "> - Jason Brownlee, *Imbalanced Classification with Python* (2020)\n",
        "\n",
        "> The solution is to not split the data randomly when using k-fold cross-validation or a train-test\n",
        "split. [...] For example, we can use a version of k-fold cross-validation that preserves the imbalanced class distribution in each fold. It is called stratified k-fold cross-validation and will enforce the class distribution in each split of the data to match the distribution in the complete training dataset.\n",
        ">\n",
        "> - Jason Brownlee, *Imbalanced Classification with Python* (2020)\n",
        "\n",
        "> Sampling is only performed on the training dataset, the dataset used by an algorithm to\n",
        "learn a model. It is not performed on the holdout test or validation dataset.\n",
        ">\n",
        "> - Jason Brownlee, *Imbalanced Classification with Python* (2020)\n",
        "\n",
        "- Stratified k-folding CrossValidation\n",
        "- Random Downsampling\n",
        "- Adding data as kind of Oversampling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6c8aPmEOdYKN"
      },
      "source": [
        "#### Adding new Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNsGXoKYdYKO"
      },
      "source": [
        "Describing the imbalance of this dataset in terms of ration is 1:500. The dataset presents sever imbalance. By adding new data to the training set with text generated by ChatGPT 3, i desire to make it become near (1:100). To achieve this i need to add **10** generated text to the dataset.\n",
        "\n",
        "This will modify the true distribution from the real dataset, but only 3 element in the minority class is not enough to apply stratified 10-fold cross validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "nahQnHEBdYKO",
        "outputId": "a45cd2ec-6504-406e-c184-ef921820c04d"
      },
      "outputs": [],
      "source": [
        "target_data = pd.concat([initial_dataset,new_data],ignore_index=True)\n",
        "target_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65Y4787kdYKP"
      },
      "source": [
        "## Data Feature Engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "chXVmCzYdYKP"
      },
      "source": [
        "### Training a Tokenizer\n",
        "Reading the competition discussions lead me to this [Notebook](https://www.kaggle.com/code/datafan07/train-your-own-tokenizer), where is suggested to add words with typos into the vocabulary for better performance by training a tokenizer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tokenizers import (\n",
        "    decoders,\n",
        "    models,\n",
        "    normalizers,\n",
        "    pre_tokenizers,\n",
        "    processors,\n",
        "    trainers,\n",
        "    Tokenizer,\n",
        ")\n",
        "# Creating Byte-Pair Encoding tokenizer\n",
        "raw_tokenizer = Tokenizer(models.BPE(unk_token=\"[UNK]\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MkOM8WoAdYKP"
      },
      "source": [
        "##### Words Tokenizing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "AGd5b7vMdYKP",
        "outputId": "fcebe33a-2999-4ca1-d3ae-21c47918eb45"
      },
      "outputs": [],
      "source": [
        "tokenized_dataset = target_data.copy()\n",
        "tokenized_dataset[\"text\"] = target_data[\"text\"].apply(lambda x : word_tokenize(text=x))\n",
        "tokenized_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XAlZGrYvdYKR"
      },
      "source": [
        "#### EliminaciÃ³n de stopwords y de simbolos de puntuaciÃ³n."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o54idgYkdYKR"
      },
      "outputs": [],
      "source": [
        "cleaned_dataset = tokenized_dataset.copy()\n",
        "def eraseStopWordsAndPunctuation(tokenList):\n",
        "    tokens = [token.lower() for token in tokenList if token.isalpha()]  # Pasar a minÃºsculas y eliminar nÃºmeros\n",
        "    tokens = [word for word in tokens if word not in stopwords.words('english')]  # Eliminar stopwords\n",
        "    return tokens\n",
        "cleaned_dataset[\"text\"] = tokenized_dataset[\"text\"].apply(lambda l : eraseStopWordsAndPunctuation(l))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNWEuYg-dYKT"
      },
      "source": [
        "#### Text to document embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Need to add all the test documents to the training phase of embedding."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tokenized_test = test_dataset;\n",
        "tokenized_test[\"text\"] = test_dataset[\"text\"].apply(lambda x : word_tokenize(text=x))\n",
        "doc_test_dataset = test_dataset\n",
        "doc_test_dataset[\"text\"] = [doc2vec.TaggedDocument(row[2],[row[0]]) for row in tokenized_test.values]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OLUZL3pUdYKT",
        "outputId": "10d64093-182b-44e6-f64d-752c3f1176e6"
      },
      "outputs": [],
      "source": [
        "docs_dataset = tokenized_dataset.copy()\n",
        "docs_dataset[\"text\"] = [doc2vec.TaggedDocument(row[2],[row[0]]) for row in tokenized_dataset.values]\n",
        "#docs_dataset[\"text\"] = [docs_dataset[\"text\"] = [doc2vec.TaggedDocument(row[2],[row[0]]) for row in tokenized_dataset.values]\n",
        "docs_dataset[\"text\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nGdh1QT7dYKT",
        "outputId": "d7baeedb-2fc4-4238-82e1-8224e92bddaa"
      },
      "outputs": [],
      "source": [
        "docs = pd.concat([docs_dataset[\"text\"],doc_test_dataset[\"text\"]])\n",
        "doc_model = doc2vec.Doc2Vec(documents=docs,vector_size=100)\n",
        "doc_model.train(docs,total_examples=tokenized_dataset.shape[0],epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBGZJYB0dYKT",
        "outputId": "154280e2-5dcc-4c7c-95e1-3f66b5bd4ac0"
      },
      "outputs": [],
      "source": [
        "doc_model.dv[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "Ke4rS-oJdYKi",
        "outputId": "a6efe2c2-57d9-4854-df41-a381597c5c2f"
      },
      "outputs": [],
      "source": [
        "arr = [doc_model.dv[docs_dataset[\"text\"][index].tags] for index in range (0,docs_dataset.shape[0])]\n",
        "embeddings_dataset = pd.DataFrame(np.reshape(arr,(1388, 100)))\n",
        "embeddings_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "Sop_gw5PdYKj",
        "outputId": "489cc0f3-00c3-476a-c619-89a7dc34fe64"
      },
      "outputs": [],
      "source": [
        "embeddings_dataset.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XL1gXWWodYKj"
      },
      "source": [
        "#### Normalizar embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5XdVRiYOdYKj",
        "outputId": "fdec5bf1-af94-4e9a-f178-6a6c7c01367d"
      },
      "outputs": [],
      "source": [
        "embeddings_dataset[\"norm\"]=np.linalg.norm(embeddings_dataset, axis=1)\n",
        "embeddings_dataset[\"norm\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "Y-ns5umfdYKj",
        "outputId": "e0e26dd1-7bc0-4a9e-d7c6-199d29518bec"
      },
      "outputs": [],
      "source": [
        "norm_embeddings_dataset = pd.DataFrame(np.apply_along_axis(lambda x: x / np.linalg.norm(x), axis=1, arr=embeddings_dataset))\n",
        "norm_embeddings_dataset[\"normalized_norm\"] = (embeddings_dataset['norm'] - embeddings_dataset['norm'].min()) / (embeddings_dataset['norm'].max() - embeddings_dataset['norm'].min())\n",
        "norm_embeddings_dataset.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2jUZ8xrgdYKj"
      },
      "outputs": [],
      "source": [
        "norm_embeddings_dataset = norm_embeddings_dataset.drop([100],axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 826
        },
        "id": "MwmoLIkHdYKk",
        "outputId": "ce49eba2-4bc9-4547-b019-5ce71a71e360"
      },
      "outputs": [],
      "source": [
        "pre_processed_data = pd.concat([docs_dataset,norm_embeddings_dataset],axis=1)\n",
        "#pre_processed_data = pd.concat([docs_dataset,embeddings_dataset],axis=1)\n",
        "pre_processed_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ok4YnFIkdYKk"
      },
      "source": [
        "### Infered Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5LK85lV3dYKk"
      },
      "outputs": [],
      "source": [
        "#cantidad de palabra\n",
        "#cantidad de oraciones\n",
        "#cantidad de puntos\n",
        "#cantidad de comas\n",
        "#cantidad de apostrofes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jV2-xzMhdYKk"
      },
      "outputs": [],
      "source": [
        "pre_processed_data = pre_processed_data.drop(\"text\",axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "KKJrJzEWdYKl",
        "outputId": "50ad4a58-1b24-408d-db60-c5bad8697938"
      },
      "outputs": [],
      "source": [
        "pre_processed_data.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pboIBijydYKl"
      },
      "source": [
        "## Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sieb_gK4dYKl"
      },
      "outputs": [],
      "source": [
        "def downsampling(X_train,y_train,rand_state,ratio):\n",
        "    # Concatenate X_train and y_train for ease of downsampling\n",
        "    train_data = pd.concat([X_train, y_train], axis=1)\n",
        "\n",
        "    # Identify the class with the majority of instances\n",
        "    majority_class = train_data[y_train.name].value_counts().idxmax()\n",
        "\n",
        "    # Separate instances of each class\n",
        "    majority_class_data = train_data[train_data[y_train.name] == majority_class]\n",
        "    minority_class_data = train_data[train_data[y_train.name] != majority_class]\n",
        "\n",
        "\n",
        "    currRatio = len(majority_class_data) / len(minority_class_data)\n",
        "    if(currRatio<=ratio):\n",
        "        raise ValueError(f\"El ratio de entrada debe ser menor al ratio actual.r={currRatio}\")\n",
        "\n",
        "\n",
        "    # Downsample the majority class to match the number of instances in the minority class\n",
        "    downsampled_majority_class_data = resample(\n",
        "        majority_class_data,\n",
        "        replace=False,\n",
        "        n_samples=math.floor(ratio*len(minority_class_data)),\n",
        "        random_state=rand_state\n",
        "    )\n",
        "\n",
        "    # Combine the downsampled majority class with the minority class\n",
        "    downsampled_train_data = pd.concat([downsampled_majority_class_data, minority_class_data])\n",
        "\n",
        "    # Shuffle the data to avoid any order-based patterns\n",
        "    downsampled_train_data = downsampled_train_data.sample(frac=1, random_state=rand_state)\n",
        "\n",
        "    # Separate X_train and y_train after downsampling\n",
        "    X_train_downsampled = downsampled_train_data.drop(columns=[y_train.name])\n",
        "    y_train_downsampled = downsampled_train_data[y_train.name]\n",
        "\n",
        "    return X_train_downsampled, y_train_downsampled"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Arquitecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "input = keras.Input(shape=(pre_processed_data.shape[1]-2,))\n",
        "x = keras.layers.Dense(pre_processed_data.shape[1]-2,activation=\"relu\")(input)\n",
        "output = keras.layers.Dense(1,activation=\"sigmoid\")(x)\n",
        "\n",
        "NNmodel = keras.Model(input,output)\n",
        "\n",
        "NNmodel.compile(optimizer='adam',\n",
        "               loss=keras.losses.BinaryCrossentropy(),\n",
        "               metrics=[keras.metrics.AUC()])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "eE-YSa9jdYKm",
        "outputId": "1017a0f1-e1de-49da-ed83-603324aa1644"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "rand_state= random.randint(0,1000)\n",
        "#NN training with 10-fold cross-validation stratified with random under-sampling technic for imbalanced data\n",
        "X = pre_processed_data.drop([\"id\",\"generated\"],axis=1)\n",
        "Y = pre_processed_data[\"generated\"]\n",
        "folds = StratifiedKFold(10,shuffle=True,random_state=rand_state)\n",
        "for fold, (train_index, val_index) in enumerate(folds.split(X,Y)):\n",
        "    X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
        "    y_train, y_val = Y.iloc[train_index], Y.iloc[val_index]\n",
        "\n",
        "    X_train_dwns, y_train_dwns = downsampling(X_train,y_train,rand_state,ratio=10)\n",
        "\n",
        "    #print(f\"Fold {fold + 1}: Train {len(train_index)} samples, Validation {len(val_index)} samples\")\n",
        "    #print(f\"TRAIN:({y_train[y_train==0].size}:{y_train[y_train==1].size})\")\n",
        "    print(f\"DOWNSAMPLED:({y_train_dwns[y_train_dwns==0].size}:{y_train_dwns[y_train_dwns==1].size})\")\n",
        "    #print(f\"VAL:({y_val[y_val==0].size}:{y_val[y_val==1].size})\")\n",
        "\n",
        "    NNmodel.fit(X_train_dwns,\n",
        "                y_train_dwns,\n",
        "                validation_data=(X_val,y_val),\n",
        "                epochs=15)\n",
        "ROCplot(NNmodel,X,Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ub2SWyaC9uL2",
        "outputId": "d63e26ff-e443-4621-9757-f9444e0fdfa6"
      },
      "outputs": [],
      "source": [
        "pred = list(map(lambda pred : 1 if pred > 0.5 else 0,NNmodel.predict(x=X)))\n",
        "confusion_matrix(pred,Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o5dVLLxVyjOg",
        "outputId": "4d54fa2d-90ac-45bf-fddb-16e7cebe5806"
      },
      "outputs": [],
      "source": [
        "NNmodel.predict(x=pd.DataFrame(X.iloc[1385]).transpose())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RY59QZYXdYKm"
      },
      "source": [
        "## Model test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "arr = [doc_model.dv[id] for id in tokenized_test[\"id\"]]\n",
        "test_embeddings_dataset = pd.DataFrame(arr)\n",
        "test_embeddings_dataset[\"norm\"]=np.linalg.norm(test_embeddings_dataset, axis=1)\n",
        "norm_test_dataset = pd.DataFrame(np.apply_along_axis(lambda x: x / np.linalg.norm(x), axis=1, arr=test_embeddings_dataset))\n",
        "norm_test_dataset[\"normalized_norm\"] = (test_embeddings_dataset['norm'] - test_embeddings_dataset['norm'].min()) / (test_embeddings_dataset['norm'].max() - test_embeddings_dataset['norm'].min())\n",
        "pre_processed_test_data = pd.concat([tokenized_test,norm_test_dataset],axis=1)\n",
        "X_test = pre_processed_test_data.drop([\"id\",\"text\",100],axis=1)\n",
        "submition = pd.DataFrame()\n",
        "submition[\"id\"]=pre_processed_test_data[\"id\"].to_numpy()\n",
        "submition[\"generated\"]=NNmodel.predict(x=X_test)\n",
        "submition[\"generated\"] = submition[\"generated\"].apply(lambda x : round(x,2))\n",
        "submition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "submition.to_csv(\"../data/submission.csv\",index=False)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0rc1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
