{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_aB82fSvdYKB"
      },
      "source": [
        "# LLM - Detect AI Generated Text\n",
        "## Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7itjdvI9dYKD",
        "outputId": "af42ede1-292a-43ea-8e85-bdb1a11a3d73"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /home/mrtc101/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /home/mrtc101/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "/home/mrtc101/Desktop/ciencias de la computacion/Cursado/4.2Inteligencia Artificial 2/Final/venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "2024-01-07 16:55:06.991250: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-01-07 16:55:06.991296: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-01-07 16:55:07.020320: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-01-07 16:55:07.083396: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-01-07 16:55:08.167807: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from nltk.tokenize import word_tokenize,sent_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from gensim.corpora import Dictionary\n",
        "from gensim.models import word2vec\n",
        "from gensim.models import doc2vec\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.utils import resample\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from sklearn.metrics import roc_curve ,precision_recall_curve\n",
        "from sklearn.metrics import auc\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from tokenizers import (\n",
        "    decoders,\n",
        "    models,\n",
        "    normalizers,\n",
        "    pre_tokenizers,\n",
        "    processors,\n",
        "    trainers,\n",
        "    Tokenizer,\n",
        ")\n",
        "from transformers import PreTrainedTokenizerFast\n",
        "\n",
        "import keras\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "4LBr4vwNdYKE"
      },
      "outputs": [],
      "source": [
        "initial_dataset = pd.read_csv(\"../../data/train_essays.csv\")\n",
        "prompts_dataset = pd.read_csv(\"../../data/train_prompts.csv\")\n",
        "new_data = pd.read_csv(\"../../data/new_essays_V1.csv\")\n",
        "test_dataset = pd.read_csv(\"../../data/test_essays.csv\")\n",
        "download_data_1 = pd.read_csv(\"../../data/train_v3_drcat_01.csv\")\n",
        "download_data_2 = pd.read_csv(\"../../data/train_v3_drcat_01.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZA-apgXdYKF"
      },
      "source": [
        "## Data analisis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "dG45LDWZdYKF",
        "outputId": "79d8fa5c-2d89-4075-ff59-2012af444706"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>prompt_id</th>\n",
              "      <th>text</th>\n",
              "      <th>generated</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0059830c</td>\n",
              "      <td>0</td>\n",
              "      <td>Cars. Cars have been around since they became ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>005db917</td>\n",
              "      <td>0</td>\n",
              "      <td>Transportation is a large necessity in most co...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>008f63e3</td>\n",
              "      <td>0</td>\n",
              "      <td>\"America's love affair with it's vehicles seem...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>00940276</td>\n",
              "      <td>0</td>\n",
              "      <td>How often do you ride in a car? Do you drive a...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>00c39458</td>\n",
              "      <td>0</td>\n",
              "      <td>Cars are a wonderful thing. They are perhaps o...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1373</th>\n",
              "      <td>fe6ff9a5</td>\n",
              "      <td>1</td>\n",
              "      <td>There has been a fuss about the Elector Colleg...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1374</th>\n",
              "      <td>ff669174</td>\n",
              "      <td>0</td>\n",
              "      <td>Limiting car usage has many advantages. Such a...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1375</th>\n",
              "      <td>ffa247e0</td>\n",
              "      <td>0</td>\n",
              "      <td>There's a new trend that has been developing f...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1376</th>\n",
              "      <td>ffc237e9</td>\n",
              "      <td>0</td>\n",
              "      <td>As we all know cars are a big part of our soci...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1377</th>\n",
              "      <td>ffe1ca0d</td>\n",
              "      <td>0</td>\n",
              "      <td>Cars have been around since the 1800's and hav...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1378 rows Ã— 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            id  prompt_id                                               text  \\\n",
              "0     0059830c          0  Cars. Cars have been around since they became ...   \n",
              "1     005db917          0  Transportation is a large necessity in most co...   \n",
              "2     008f63e3          0  \"America's love affair with it's vehicles seem...   \n",
              "3     00940276          0  How often do you ride in a car? Do you drive a...   \n",
              "4     00c39458          0  Cars are a wonderful thing. They are perhaps o...   \n",
              "...        ...        ...                                                ...   \n",
              "1373  fe6ff9a5          1  There has been a fuss about the Elector Colleg...   \n",
              "1374  ff669174          0  Limiting car usage has many advantages. Such a...   \n",
              "1375  ffa247e0          0  There's a new trend that has been developing f...   \n",
              "1376  ffc237e9          0  As we all know cars are a big part of our soci...   \n",
              "1377  ffe1ca0d          0  Cars have been around since the 1800's and hav...   \n",
              "\n",
              "      generated  \n",
              "0             0  \n",
              "1             0  \n",
              "2             0  \n",
              "3             0  \n",
              "4             0  \n",
              "...         ...  \n",
              "1373          0  \n",
              "1374          0  \n",
              "1375          0  \n",
              "1376          0  \n",
              "1377          0  \n",
              "\n",
              "[1378 rows x 4 columns]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "initial_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A5Ufk5XndYKG",
        "outputId": "3450810c-2adc-4c00-fc1f-c2d1456b9634"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "id           object\n",
              "prompt_id     int64\n",
              "text         object\n",
              "generated     int64\n",
              "dtype: object"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "initial_dataset.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y5ClvnTtdYKH",
        "outputId": "196e4691-b015-4bb9-af88-4c546b343f5e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1378, 4)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "initial_dataset.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "M6w38AusdYKH",
        "outputId": "b1fdc793-13a5-4d99-d115-2f2e700905a3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>prompt_id</th>\n",
              "      <th>generated</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1378.000000</td>\n",
              "      <td>1378.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.486212</td>\n",
              "      <td>0.002177</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.499991</td>\n",
              "      <td>0.046625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         prompt_id    generated\n",
              "count  1378.000000  1378.000000\n",
              "mean      0.486212     0.002177\n",
              "std       0.499991     0.046625\n",
              "min       0.000000     0.000000\n",
              "25%       0.000000     0.000000\n",
              "50%       0.000000     0.000000\n",
              "75%       1.000000     0.000000\n",
              "max       1.000000     1.000000"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "initial_dataset.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNIWdXOudYKJ"
      },
      "source": [
        "`generated` - Whether the essay was written by a student (0) or generated by an LLM (1). This field is the target and is not present in test_essays.csv."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "opIz_MYjdYKK",
        "outputId": "a0779745-675b-420c-ab35-9f76ed996bd4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "generated\n",
              "0    1375\n",
              "1       3\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "initial_dataset.value_counts(\"generated\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dR2Ut5ModYKK",
        "outputId": "7116634c-ea81-4443-d71c-ec79f3823973"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "generated\n",
              "0    1375\n",
              "1       3\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "generated = initial_dataset.value_counts(\"generated\")\n",
        "generated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F2vi4-PUdYKL",
        "outputId": "8462130b-38f0-4589-853a-ac85d77928d1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "generated\n",
              "0    0.997823\n",
              "1    0.002177\n",
              "Name: count, dtype: float64"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "generated = generated.apply(lambda x : x/initial_dataset.shape[0])\n",
        "generated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "T-caBmNmdYKL",
        "outputId": "0e2f175e-45cc-45ad-be23-6aa097778e24"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 400x300 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig, ax = plt.subplots(figsize=(4,3))\n",
        "fig.suptitle(\"Generated\")\n",
        "ax.bar(\n",
        "    x=[\"By studentes\",\"By LLM\"],\n",
        "    height=generated,\n",
        "    width=0.2,\n",
        "    color=[\"red\",\"green\"],\n",
        "    align=\"center\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "cEvFa1lQdYKL",
        "outputId": "cda624f9-81ba-42a5-eb31-d723b1f7ac01"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>prompt_id</th>\n",
              "      <th>prompt_name</th>\n",
              "      <th>instructions</th>\n",
              "      <th>source_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Car-free cities</td>\n",
              "      <td>Write an explanatory essay to inform fellow ci...</td>\n",
              "      <td># In German Suburb, Life Goes On Without Cars ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Does the electoral college work?</td>\n",
              "      <td>Write a letter to your state senator in which ...</td>\n",
              "      <td># What Is the Electoral College? by the Office...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   prompt_id                       prompt_name  \\\n",
              "0          0                   Car-free cities   \n",
              "1          1  Does the electoral college work?   \n",
              "\n",
              "                                        instructions  \\\n",
              "0  Write an explanatory essay to inform fellow ci...   \n",
              "1  Write a letter to your state senator in which ...   \n",
              "\n",
              "                                         source_text  \n",
              "0  # In German Suburb, Life Goes On Without Cars ...  \n",
              "1  # What Is the Electoral College? by the Office...  "
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prompts_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJArVOlmdYKL",
        "outputId": "5db7ce67-19ba-45b9-9925-b71fe40f2819"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "prompt_id\n",
              "0    708\n",
              "1    670\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prompts = initial_dataset.value_counts(\"prompt_id\")\n",
        "prompts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "O-fg234YdYKM",
        "outputId": "3a4c4755-4c18-4789-c7ed-b079cfffd362"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 400x300 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig, ax = plt.subplots(figsize=(4,3))\n",
        "fig.suptitle(\"Prompts\")\n",
        "ax.bar(\n",
        "    x=[\"Car-free cities\",\"Does the electoral college work?\"],\n",
        "    height=prompts,\n",
        "    width=0.2,\n",
        "    color=[\"red\",\"green\"],\n",
        "    align=\"center\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1378, 4)\n",
            "(1378, 4)\n"
          ]
        }
      ],
      "source": [
        "print(initial_dataset.shape)\n",
        "initial_dataset.drop_duplicates(subset=[\"text\"],inplace=True)\n",
        "initial_dataset.reset_index(drop=True, inplace=True)\n",
        "print(initial_dataset.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yHzxLez5dYKM"
      },
      "source": [
        "## Handle imbalanced Data\n",
        "\n",
        "> Because the class distribution is not balanced, most machine learning algorithms will perform\n",
        "poorly and require modification to avoid simply predicting the majority class in all cases.\n",
        "Additionally, metrics like classification accuracy lose their meaning and alternate methods for\n",
        "evaluating predictions on imbalanced examples are required, like ROC area under curve. This is\n",
        "the foundational challenge of imbalanced classification.\n",
        ">\n",
        "> - Jason Brownlee, *Imbalanced Classification with Python* (2020)\n",
        "\n",
        "> If we think about feature space spatially, we might like all examples in one class to be located on one part\n",
        "of the space, and those from the other class to appear in another part of the space. [...]\n",
        ">This is rarely the case, and it is more likely that each class has multiple **concepts** resulting in multiple different groups or clusters of examples in feature space.\n",
        ">\n",
        "> - Jason Brownlee, *Imbalanced Classification with Python* (2020)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-53GminWdYKM"
      },
      "source": [
        "### Metrics for Imbalanced Data\n",
        "\n",
        ">Although widely used, classification accuracy is almost universally inappropriate for imbalanced classification. The reason is, a high accuracy (or low error) is achievable by a no skill model that only predicts the majority class. [...]\n",
        ">\n",
        "> - Jason Brownlee, *Imbalanced Classification with Python* (2020)\n",
        "\n",
        ">There are two groups of metrics that may be useful for imbalanced classification because they focus on one class; they are sensitivity-specificity and precision-recall.\n",
        ">\n",
        "> - Jason Brownlee, *Imbalanced Classification with Python* (2020)\n",
        "\n",
        ">One limitation of these metrics is that they assume that the class distribution observed in the training dataset will match the distribution in the test set and in real data when the model is used to make predictions. [...] Ranking metrics donâ€™t make any assumptions about class distributions.\n",
        ">\n",
        "> - Jason Brownlee, *Imbalanced Classification with Python* (2020)\n",
        "\n",
        ">The most commonly used ranking metric is the ROC Curve or ROC Analysis. ROC is an\n",
        "acronym that means Receiver Operating Characteristic and summarizes a field of study for\n",
        "analyzing binary classifiers based on their ability to discriminate classes.\n",
        ">\n",
        "> - Jason Brownlee, *Imbalanced Classification with Python* (2020)\n",
        "\n",
        ">Although generally effective, the ROC Curve and ROC AUC can be optimistic under a severe class imbalance, especially when the number of examples in the minority class is small.\n",
        "An alternative to the ROC Curve is the precision-recall curve that can be used in a similar way, although focuses on the performance of the classifier on the minority class.\n",
        ">\n",
        "> - Jason Brownlee, *Imbalanced Classification with Python* (2020)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5EjLehn3dYKN"
      },
      "source": [
        "#### ROC AUC curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "FvEDVQHVdYKN"
      },
      "outputs": [],
      "source": [
        "def ROCcurves(model,x_val,y_val):\n",
        "    fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(10, 4))\n",
        "    y_pred = model.predict(x_val).ravel()\n",
        "    \n",
        "    fpr, tpr , _ = roc_curve(y_val,  y_pred)\n",
        "    auc_ss = auc(fpr,tpr)\n",
        "    precision, recall, _ = precision_recall_curve(y_val,  y_pred)\n",
        "    auc_pr = auc(recall, precision)\n",
        "\n",
        "    # Primer subgrÃ¡fico\n",
        "    axs[0].plot([0, 1], [0, 1], color='gray', lw=1, linestyle='--', label='AUC = 0.50')\n",
        "    axs[0].plot(fpr,tpr, label='ROC curve', color='blue')\n",
        "    axs[0].set_title(f'ROC curve = {round(auc_ss,3)}')\n",
        "    axs[0].set_xlabel('FalsePositiveRate')\n",
        "    axs[0].set_ylabel('TruePositiveRate')\n",
        "    axs[0].legend()\n",
        "    # Segundo subgrÃ¡fico\n",
        "    axs[1].plot([0, 1], [0,0], color='gray', lw=1, linestyle='--', label='AUC = 0.0')\n",
        "    axs[1].plot(recall, precision, label='ROC-RP curve', color='orange')\n",
        "    axs[1].set_title(f'ROC-RP curve = {round(auc_pr,3)}')\n",
        "    axs[1].set_xlabel('Recall')\n",
        "    axs[1].set_ylabel('Precision')\n",
        "    axs[1].legend()\n",
        "    plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Rqz4YundYKN"
      },
      "source": [
        "### Data Sampling for imbalanced data\n",
        "\n",
        "> Sadly, k-fold cross-validation is not appropriate for evaluating imbalanced classifiers.\n",
        "[...]\n",
        "The reason is that the data is split into k-folds with a uniform probability distribution. This might work fine for data with a balanced class distribution, but when the distribution is severely skewed, it is likely that one or more folds will have few or no examples from the minority class.\n",
        ">\n",
        "> - Jason Brownlee, *Imbalanced Classification with Python* (2020)\n",
        "\n",
        "> The solution is to not split the data randomly when using k-fold cross-validation or a train-test\n",
        "split. [...] For example, we can use a version of k-fold cross-validation that preserves the imbalanced class distribution in each fold. It is called stratified k-fold cross-validation and will enforce the class distribution in each split of the data to match the distribution in the complete training dataset.\n",
        ">\n",
        "> - Jason Brownlee, *Imbalanced Classification with Python* (2020)\n",
        "\n",
        "> Sampling is only performed on the training dataset, the dataset used by an algorithm to\n",
        "learn a model. It is not performed on the holdout test or validation dataset.\n",
        ">\n",
        "> - Jason Brownlee, *Imbalanced Classification with Python* (2020)\n",
        "\n",
        "- Stratified k-folding CrossValidation\n",
        "- Random Downsampling\n",
        "- Adding data as kind of Oversampling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6c8aPmEOdYKN"
      },
      "source": [
        "## Adding new Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNsGXoKYdYKO"
      },
      "source": [
        "Describing the imbalance of this dataset in terms of ration is 1:500. The dataset presents sever imbalance. Previous aproches using only 20 new LLM generated examples manually and random Downsampling technic, didn't reach a higher score than 0.56. \n",
        "\n",
        "Concluding that more new data is needed, i downloaded data shared by competitors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "download_data_1[\"prompt_id\"] = download_data_1[\"prompt_name\"].apply(lambda name : 0 if name == \"Car-free cities\" else 1 if name == \"Does the electoral college work?\" else 21 )\n",
        "download_data_1 = download_data_1[[\"prompt_id\",\"text\",\"label\"]].rename(columns={\"label\":\"generated\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "new_data = pd.concat([new_data,download_data_1],axis=0,ignore_index=True)\n",
        "new_data[\"id\"] = range(0,new_data.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>prompt_id</th>\n",
              "      <th>text</th>\n",
              "      <th>generated</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>The Advantages of Limiting Car Usage in Suburb...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Paris' Driving Ban: A Temporary Solution to En...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>Bogota's Car-Free Day: A Model for Sustainable...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>Shifting Trends: The Decline of Car Culture in...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>The End of Car Culture and the Rise of Sustain...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65525</th>\n",
              "      <td>65525</td>\n",
              "      <td>1</td>\n",
              "      <td>\\n\\nDear Senator,\\n\\nI am writing to you regar...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65526</th>\n",
              "      <td>65526</td>\n",
              "      <td>1</td>\n",
              "      <td>\\n\\nI remember the day distinctively. I was si...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65527</th>\n",
              "      <td>65527</td>\n",
              "      <td>1</td>\n",
              "      <td>\\n\\nDear Senator, \\n\\nI am writing this letter...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65528</th>\n",
              "      <td>65528</td>\n",
              "      <td>1</td>\n",
              "      <td>\\n\\nDear Senator,\\n\\nI am writing to urge you ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65529</th>\n",
              "      <td>65529</td>\n",
              "      <td>1</td>\n",
              "      <td>\\n\\nIt was a typical summer afternoon in my ho...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>65530 rows Ã— 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          id  prompt_id                                               text  \\\n",
              "0          0          0  The Advantages of Limiting Car Usage in Suburb...   \n",
              "1          1          0  Paris' Driving Ban: A Temporary Solution to En...   \n",
              "2          2          0  Bogota's Car-Free Day: A Model for Sustainable...   \n",
              "3          3          0  Shifting Trends: The Decline of Car Culture in...   \n",
              "4          4          0  The End of Car Culture and the Rise of Sustain...   \n",
              "...      ...        ...                                                ...   \n",
              "65525  65525          1  \\n\\nDear Senator,\\n\\nI am writing to you regar...   \n",
              "65526  65526          1  \\n\\nI remember the day distinctively. I was si...   \n",
              "65527  65527          1  \\n\\nDear Senator, \\n\\nI am writing this letter...   \n",
              "65528  65528          1  \\n\\nDear Senator,\\n\\nI am writing to urge you ...   \n",
              "65529  65529          1  \\n\\nIt was a typical summer afternoon in my ho...   \n",
              "\n",
              "       generated  \n",
              "0              1  \n",
              "1              1  \n",
              "2              1  \n",
              "3              1  \n",
              "4              1  \n",
              "...          ...  \n",
              "65525          1  \n",
              "65526          1  \n",
              "65527          1  \n",
              "65528          1  \n",
              "65529          1  \n",
              "\n",
              "[65530 rows x 4 columns]"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "new_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "nahQnHEBdYKO",
        "outputId": "a45cd2ec-6504-406e-c184-ef921820c04d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>prompt_id</th>\n",
              "      <th>text</th>\n",
              "      <th>generated</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0059830c</td>\n",
              "      <td>0</td>\n",
              "      <td>Cars. Cars have been around since they became ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>005db917</td>\n",
              "      <td>0</td>\n",
              "      <td>Transportation is a large necessity in most co...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>008f63e3</td>\n",
              "      <td>0</td>\n",
              "      <td>\"America's love affair with it's vehicles seem...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>00940276</td>\n",
              "      <td>0</td>\n",
              "      <td>How often do you ride in a car? Do you drive a...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>00c39458</td>\n",
              "      <td>0</td>\n",
              "      <td>Cars are a wonderful thing. They are perhaps o...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66903</th>\n",
              "      <td>65525</td>\n",
              "      <td>1</td>\n",
              "      <td>\\n\\nDear Senator,\\n\\nI am writing to you regar...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66904</th>\n",
              "      <td>65526</td>\n",
              "      <td>1</td>\n",
              "      <td>\\n\\nI remember the day distinctively. I was si...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66905</th>\n",
              "      <td>65527</td>\n",
              "      <td>1</td>\n",
              "      <td>\\n\\nDear Senator, \\n\\nI am writing this letter...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66906</th>\n",
              "      <td>65528</td>\n",
              "      <td>1</td>\n",
              "      <td>\\n\\nDear Senator,\\n\\nI am writing to urge you ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66907</th>\n",
              "      <td>65529</td>\n",
              "      <td>1</td>\n",
              "      <td>\\n\\nIt was a typical summer afternoon in my ho...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>66908 rows Ã— 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             id  prompt_id                                               text  \\\n",
              "0      0059830c          0  Cars. Cars have been around since they became ...   \n",
              "1      005db917          0  Transportation is a large necessity in most co...   \n",
              "2      008f63e3          0  \"America's love affair with it's vehicles seem...   \n",
              "3      00940276          0  How often do you ride in a car? Do you drive a...   \n",
              "4      00c39458          0  Cars are a wonderful thing. They are perhaps o...   \n",
              "...         ...        ...                                                ...   \n",
              "66903     65525          1  \\n\\nDear Senator,\\n\\nI am writing to you regar...   \n",
              "66904     65526          1  \\n\\nI remember the day distinctively. I was si...   \n",
              "66905     65527          1  \\n\\nDear Senator, \\n\\nI am writing this letter...   \n",
              "66906     65528          1  \\n\\nDear Senator,\\n\\nI am writing to urge you ...   \n",
              "66907     65529          1  \\n\\nIt was a typical summer afternoon in my ho...   \n",
              "\n",
              "       generated  \n",
              "0              0  \n",
              "1              0  \n",
              "2              0  \n",
              "3              0  \n",
              "4              0  \n",
              "...          ...  \n",
              "66903          1  \n",
              "66904          1  \n",
              "66905          1  \n",
              "66906          1  \n",
              "66907          1  \n",
              "\n",
              "[66908 rows x 4 columns]"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "target_data = pd.concat([initial_dataset,new_data],ignore_index=True,axis=0)\n",
        "target_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(66908, 4)\n",
            "(65355, 4)\n"
          ]
        }
      ],
      "source": [
        "print(target_data.shape)\n",
        "target_data.drop_duplicates(subset=[\"text\"],inplace=True,keep=\"first\")\n",
        "print(target_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "text\n",
              "<class 'str'>      65354\n",
              "<class 'float'>        1\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "target_data[\"text\"].apply(lambda x : type(x)).value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>prompt_id</th>\n",
              "      <th>text</th>\n",
              "      <th>generated</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>46318</th>\n",
              "      <td>44940</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          id  prompt_id text  generated\n",
              "46318  44940          0  NaN          1"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "target_data[target_data[\"text\"].apply(lambda x : type(x))==type(0.01)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "target_data=target_data.dropna()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65Y4787kdYKP"
      },
      "source": [
        "## Data Feature Engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "chXVmCzYdYKP"
      },
      "source": [
        "### Training a Tokenizer\n",
        "Reading the competition discussions lead me to this [Notebook](https://www.kaggle.com/code/datafan07/train-your-own-tokenizer), where is suggested to add words with typos into the vocabulary for better performance by training a tokenizer.\n",
        "\n",
        "1. normalization\n",
        "2. pre-tokenization\n",
        "3. model\n",
        "4. post-processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ">ByteLevel: \n",
        ">\n",
        ">Splits on whitespaces while remapping all the bytes to a set of visible characters. This technique as been introduced by OpenAI with GPT-2 and has some more or less nice properties:\n",
        "> - Since it maps on bytes, a tokenizer using this only requires 256 characters as initial alphabet (the number of values a byte can have), as opposed to the 130,000+ Unicode characters.\n",
        "> - A consequence of the previous point is that it is absolutely unnecessary to have an unknown token using this since we can represent anything with 256 tokens (Youhou!! ðŸŽ‰ðŸŽ‰)\n",
        "> - For non ascii characters, it gets completely unreadable, but it works nonetheless!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Creating Byte-Pair Encoding tokenizer\n",
        "raw_tokenizer = Tokenizer(models.BPE(unk_token=\"[UNK]\"))\n",
        "#Cleaning\n",
        "raw_tokenizer.normalizer =  normalizers.Sequence(\n",
        "    [\n",
        "        normalizers.NFC(),\n",
        "        normalizers.Lowercase(),\n",
        "        normalizers.Replace(\"\\n\",\" \"),\n",
        "        normalizers.Replace(\"\\r\",\" \"),\n",
        "        normalizers.Replace(\"\\t\",\" \")\n",
        "    ]    \n",
        "    )\n",
        "#First tokenization\n",
        "raw_tokenizer.pre_tokenizer = pre_tokenizers.ByteLevel()\n",
        "#Training\n",
        "special_tokens = [\"[UNK]\", \"[PAD]\", \"[CLS]\", \"[SEP]\", \"[MASK]\"]\n",
        "trainer = trainers.BpeTrainer(show_progress=True,special_tokens=special_tokens)\n",
        "\n",
        "def data_iter(dataset):\n",
        "    \"\"\"\n",
        "    A generator function for iterating over a dataset in chunks.\n",
        "    \"\"\"    \n",
        "    for i in range(0, len(dataset), 1000):\n",
        "        yield dataset[i : i + 1000][\"text\"]\n",
        "\n",
        "raw_tokenizer.train_from_iterator(data_iter(target_data),trainer)\n",
        "\n",
        "tokenizer = PreTrainedTokenizerFast(\n",
        "    tokenizer_object=raw_tokenizer,\n",
        "    unk_token=\"[UNK]\",\n",
        "    pad_token=\"[PAD]\",\n",
        "    cls_token=\"[CLS]\",\n",
        "    sep_token=\"[SEP]\",\n",
        "    mask_token=\"[MASK]\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"martÃ­n's bag\""
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "raw_tokenizer.normalizer.normalize_str(\"MartÃ­n's bag\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Ä mart', 'Ãƒ', 'Åƒ', 'n', \"'s\", 'Ä bag']"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.tokenize(\"MartÃ­n's bag\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MkOM8WoAdYKP"
      },
      "source": [
        "##### Words Tokenizing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "AGd5b7vMdYKP",
        "outputId": "fcebe33a-2999-4ca1-d3ae-21c47918eb45"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>prompt_id</th>\n",
              "      <th>text</th>\n",
              "      <th>generated</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0059830c</td>\n",
              "      <td>0</td>\n",
              "      <td>[Ä cars, ., Ä cars, Ä have, Ä been, Ä around, Ä sinc...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>005db917</td>\n",
              "      <td>0</td>\n",
              "      <td>[Ä transportation, Ä is, Ä a, Ä large, Ä necessity,...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>008f63e3</td>\n",
              "      <td>0</td>\n",
              "      <td>[Ä \", america, 's, Ä love, Ä affair, Ä with, Ä it, ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>00940276</td>\n",
              "      <td>0</td>\n",
              "      <td>[Ä how, Ä often, Ä do, Ä you, Ä ride, Ä in, Ä a, Ä car...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>00c39458</td>\n",
              "      <td>0</td>\n",
              "      <td>[Ä cars, Ä are, Ä a, Ä wonderful, Ä thing, ., Ä they...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66903</th>\n",
              "      <td>65525</td>\n",
              "      <td>1</td>\n",
              "      <td>[Ä , Ä dear, Ä senator, ,, Ä , Ä i, Ä am, Ä writing, ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66904</th>\n",
              "      <td>65526</td>\n",
              "      <td>1</td>\n",
              "      <td>[Ä , Ä i, Ä remember, Ä the, Ä day, Ä distinctively,...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66905</th>\n",
              "      <td>65527</td>\n",
              "      <td>1</td>\n",
              "      <td>[Ä , Ä dear, Ä senator, ,, Ä Ä , Ä i, Ä am, Ä writing,...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66906</th>\n",
              "      <td>65528</td>\n",
              "      <td>1</td>\n",
              "      <td>[Ä , Ä dear, Ä senator, ,, Ä , Ä i, Ä am, Ä writing, ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66907</th>\n",
              "      <td>65529</td>\n",
              "      <td>1</td>\n",
              "      <td>[Ä , Ä it, Ä was, Ä a, Ä typical, Ä summer, Ä afterno...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>65354 rows Ã— 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             id  prompt_id                                               text  \\\n",
              "0      0059830c          0  [Ä cars, ., Ä cars, Ä have, Ä been, Ä around, Ä sinc...   \n",
              "1      005db917          0  [Ä transportation, Ä is, Ä a, Ä large, Ä necessity,...   \n",
              "2      008f63e3          0  [Ä \", america, 's, Ä love, Ä affair, Ä with, Ä it, ...   \n",
              "3      00940276          0  [Ä how, Ä often, Ä do, Ä you, Ä ride, Ä in, Ä a, Ä car...   \n",
              "4      00c39458          0  [Ä cars, Ä are, Ä a, Ä wonderful, Ä thing, ., Ä they...   \n",
              "...         ...        ...                                                ...   \n",
              "66903     65525          1  [Ä , Ä dear, Ä senator, ,, Ä , Ä i, Ä am, Ä writing, ...   \n",
              "66904     65526          1  [Ä , Ä i, Ä remember, Ä the, Ä day, Ä distinctively,...   \n",
              "66905     65527          1  [Ä , Ä dear, Ä senator, ,, Ä Ä , Ä i, Ä am, Ä writing,...   \n",
              "66906     65528          1  [Ä , Ä dear, Ä senator, ,, Ä , Ä i, Ä am, Ä writing, ...   \n",
              "66907     65529          1  [Ä , Ä it, Ä was, Ä a, Ä typical, Ä summer, Ä afterno...   \n",
              "\n",
              "       generated  \n",
              "0              0  \n",
              "1              0  \n",
              "2              0  \n",
              "3              0  \n",
              "4              0  \n",
              "...          ...  \n",
              "66903          1  \n",
              "66904          1  \n",
              "66905          1  \n",
              "66906          1  \n",
              "66907          1  \n",
              "\n",
              "[65354 rows x 4 columns]"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenized_test = test_dataset;\n",
        "tokenized_test[\"text\"] = test_dataset[\"text\"].apply(lambda x : tokenizer.tokenize(text=x))\n",
        "\n",
        "tokenized_dataset = target_data.copy()\n",
        "tokenized_dataset[\"text\"] = target_data[\"text\"].apply(lambda x : tokenizer.tokenize(x))\n",
        "tokenized_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNWEuYg-dYKT"
      },
      "source": [
        "#### Text to document embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Need to add all the test documents to the training phase of embedding."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "doc_test_dataset = test_dataset\n",
        "doc_test_dataset[\"text\"] = [doc2vec.TaggedDocument(row[2],[row[0]]) for row in tokenized_test.values]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OLUZL3pUdYKT",
        "outputId": "10d64093-182b-44e6-f64d-752c3f1176e6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0        ([Ä cars, ., Ä cars, Ä have, Ä been, Ä around, Ä sin...\n",
              "1        ([Ä transportation, Ä is, Ä a, Ä large, Ä necessity...\n",
              "2        ([Ä \", america, 's, Ä love, Ä affair, Ä with, Ä it,...\n",
              "3        ([Ä how, Ä often, Ä do, Ä you, Ä ride, Ä in, Ä a, Ä ca...\n",
              "4        ([Ä cars, Ä are, Ä a, Ä wonderful, Ä thing, ., Ä the...\n",
              "                               ...                        \n",
              "66903    ([Ä , Ä dear, Ä senator, ,, Ä , Ä i, Ä am, Ä writing,...\n",
              "66904    ([Ä , Ä i, Ä remember, Ä the, Ä day, Ä distinctively...\n",
              "66905    ([Ä , Ä dear, Ä senator, ,, Ä Ä , Ä i, Ä am, Ä writing...\n",
              "66906    ([Ä , Ä dear, Ä senator, ,, Ä , Ä i, Ä am, Ä writing,...\n",
              "66907    ([Ä , Ä it, Ä was, Ä a, Ä typical, Ä summer, Ä aftern...\n",
              "Name: text, Length: 65354, dtype: object"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "docs_dataset = tokenized_dataset.copy()\n",
        "docs_dataset[\"text\"] = [doc2vec.TaggedDocument(row[2],[row[0]]) for row in tokenized_dataset.values]\n",
        "docs_dataset[\"text\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[30], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m docs \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([docs_dataset[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m],doc_test_dataset[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m]])\n\u001b[0;32m----> 2\u001b[0m doc_model \u001b[38;5;241m=\u001b[39m \u001b[43mdoc2vec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDoc2Vec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdocs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mvector_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m35\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Desktop/ciencias de la computacion/Cursado/4.2Inteligencia Artificial 2/Final/venv/lib/python3.11/site-packages/gensim/models/doc2vec.py:296\u001b[0m, in \u001b[0;36mDoc2Vec.__init__\u001b[0;34m(self, documents, corpus_file, vector_size, dm_mean, dm, dbow_words, dm_concat, dm_tag_count, dv, dv_mapfile, comment, trim_rule, callbacks, window, epochs, shrink_windows, **kwargs)\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;66;03m# EXPERIMENTAL lockf feature; create minimal no-op lockf arrays (1 element of 1.0)\u001b[39;00m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;66;03m# advanced users should directly resize/adjust as desired after any vocab growth\u001b[39;00m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdv\u001b[38;5;241m.\u001b[39mvectors_lockf \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mones(\u001b[38;5;241m1\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mREAL)  \u001b[38;5;66;03m# 0.0 values suppress word-backprop-updates; 1.0 allows\u001b[39;00m\n\u001b[0;32m--> 296\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mDoc2Vec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43msentences\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcorpus_iterable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcorpus_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcorpus_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvector_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvector_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[43m    \u001b[49m\u001b[43msg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdm\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnull_word\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdm_concat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwindow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwindow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshrink_windows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshrink_windows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Desktop/ciencias de la computacion/Cursado/4.2Inteligencia Artificial 2/Final/venv/lib/python3.11/site-packages/gensim/models/word2vec.py:430\u001b[0m, in \u001b[0;36mWord2Vec.__init__\u001b[0;34m(self, sentences, corpus_file, vector_size, alpha, window, min_count, max_vocab_size, sample, seed, workers, min_alpha, sg, hs, negative, ns_exponent, cbow_mean, hashfxn, epochs, null_word, trim_rule, sorted_vocab, batch_words, compute_loss, callbacks, comment, max_final_vocab, shrink_windows)\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_corpus_sanity(corpus_iterable\u001b[38;5;241m=\u001b[39mcorpus_iterable, corpus_file\u001b[38;5;241m=\u001b[39mcorpus_file, passes\u001b[38;5;241m=\u001b[39m(epochs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m    429\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild_vocab(corpus_iterable\u001b[38;5;241m=\u001b[39mcorpus_iterable, corpus_file\u001b[38;5;241m=\u001b[39mcorpus_file, trim_rule\u001b[38;5;241m=\u001b[39mtrim_rule)\n\u001b[0;32m--> 430\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcorpus_iterable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcorpus_iterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcorpus_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcorpus_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal_examples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcorpus_count\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcorpus_total_words\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_alpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[43m        \u001b[49m\u001b[43mend_alpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmin_alpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompute_loss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    435\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trim_rule \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "File \u001b[0;32m~/Desktop/ciencias de la computacion/Cursado/4.2Inteligencia Artificial 2/Final/venv/lib/python3.11/site-packages/gensim/models/doc2vec.py:516\u001b[0m, in \u001b[0;36mDoc2Vec.train\u001b[0;34m(self, corpus_iterable, corpus_file, total_examples, total_words, epochs, start_alpha, end_alpha, word_count, queue_factor, report_delay, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    513\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moffsets\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m offsets\n\u001b[1;32m    514\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstart_doctags\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m start_doctags\n\u001b[0;32m--> 516\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mDoc2Vec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    517\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcorpus_iterable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcorpus_iterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcorpus_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcorpus_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtotal_examples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_examples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    519\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_alpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_alpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_alpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mend_alpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mword_count\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mword_count\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    520\u001b[0m \u001b[43m    \u001b[49m\u001b[43mqueue_factor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mqueue_factor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreport_delay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreport_delay\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Desktop/ciencias de la computacion/Cursado/4.2Inteligencia Artificial 2/Final/venv/lib/python3.11/site-packages/gensim/models/word2vec.py:1073\u001b[0m, in \u001b[0;36mWord2Vec.train\u001b[0;34m(self, corpus_iterable, corpus_file, total_examples, total_words, epochs, start_alpha, end_alpha, word_count, queue_factor, report_delay, compute_loss, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m   1070\u001b[0m     callback\u001b[38;5;241m.\u001b[39mon_epoch_begin(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m   1072\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m corpus_iterable \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1073\u001b[0m     trained_word_count_epoch, raw_word_count_epoch, job_tally_epoch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_epoch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1074\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcorpus_iterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcur_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcur_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal_examples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_examples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1075\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_words\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueue_factor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mqueue_factor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreport_delay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreport_delay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1076\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1077\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1078\u001b[0m     trained_word_count_epoch, raw_word_count_epoch, job_tally_epoch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_epoch_corpusfile(\n\u001b[1;32m   1079\u001b[0m         corpus_file, cur_epoch\u001b[38;5;241m=\u001b[39mcur_epoch, total_examples\u001b[38;5;241m=\u001b[39mtotal_examples, total_words\u001b[38;5;241m=\u001b[39mtotal_words,\n\u001b[1;32m   1080\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[0;32m~/Desktop/ciencias de la computacion/Cursado/4.2Inteligencia Artificial 2/Final/venv/lib/python3.11/site-packages/gensim/models/word2vec.py:1434\u001b[0m, in \u001b[0;36mWord2Vec._train_epoch\u001b[0;34m(self, data_iterable, cur_epoch, total_examples, total_words, queue_factor, report_delay, callbacks)\u001b[0m\n\u001b[1;32m   1431\u001b[0m     thread\u001b[38;5;241m.\u001b[39mdaemon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# make interrupting the process with ctrl+c easier\u001b[39;00m\n\u001b[1;32m   1432\u001b[0m     thread\u001b[38;5;241m.\u001b[39mstart()\n\u001b[0;32m-> 1434\u001b[0m trained_word_count, raw_word_count, job_tally \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_log_epoch_progress\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1435\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprogress_queue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjob_queue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcur_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcur_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal_examples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_examples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1436\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtotal_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_words\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreport_delay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreport_delay\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_corpus_file_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1437\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1439\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m trained_word_count, raw_word_count, job_tally\n",
            "File \u001b[0;32m~/Desktop/ciencias de la computacion/Cursado/4.2Inteligencia Artificial 2/Final/venv/lib/python3.11/site-packages/gensim/models/word2vec.py:1289\u001b[0m, in \u001b[0;36mWord2Vec._log_epoch_progress\u001b[0;34m(self, progress_queue, job_queue, cur_epoch, total_examples, total_words, report_delay, is_corpus_file_mode)\u001b[0m\n\u001b[1;32m   1286\u001b[0m unfinished_worker_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworkers\n\u001b[1;32m   1288\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m unfinished_worker_count \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 1289\u001b[0m     report \u001b[38;5;241m=\u001b[39m \u001b[43mprogress_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# blocks if workers too slow\u001b[39;00m\n\u001b[1;32m   1290\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m report \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# a thread reporting that it finished\u001b[39;00m\n\u001b[1;32m   1291\u001b[0m         unfinished_worker_count \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
            "File \u001b[0;32m/usr/lib/python3.11/queue.py:171\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    170\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_qsize():\n\u001b[0;32m--> 171\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnot_empty\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m timeout \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    173\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m must be a non-negative number\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[0;32m/usr/lib/python3.11/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "docs = pd.concat([docs_dataset[\"text\"],doc_test_dataset[\"text\"]])\n",
        "doc_model = doc2vec.Doc2Vec(documents=docs,vector_size=100,epochs=35)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBGZJYB0dYKT",
        "outputId": "154280e2-5dcc-4c7c-95e1-3f66b5bd4ac0"
      },
      "outputs": [],
      "source": [
        "doc_model.dv[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "doc_model.save(\"../../data/vecModel.bin\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "doc_model = doc2vec.Doc2Vec.load(\"../../data/vecModel.bin\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "arr = [doc_model.dv[doc_test_dataset[\"text\"][i].tags] for i in doc_test_dataset.index]\n",
        "embeddings_test_dataset = pd.DataFrame(np.reshape(arr,(len(arr), 100)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "Ke4rS-oJdYKi",
        "outputId": "a6efe2c2-57d9-4854-df41-a381597c5c2f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>90</th>\n",
              "      <th>91</th>\n",
              "      <th>92</th>\n",
              "      <th>93</th>\n",
              "      <th>94</th>\n",
              "      <th>95</th>\n",
              "      <th>96</th>\n",
              "      <th>97</th>\n",
              "      <th>98</th>\n",
              "      <th>99</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.219739</td>\n",
              "      <td>-1.110067</td>\n",
              "      <td>-1.817891</td>\n",
              "      <td>0.435371</td>\n",
              "      <td>-1.260984</td>\n",
              "      <td>-0.823853</td>\n",
              "      <td>1.171997</td>\n",
              "      <td>2.576343</td>\n",
              "      <td>1.515475</td>\n",
              "      <td>-1.234537</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.291681</td>\n",
              "      <td>1.084419</td>\n",
              "      <td>1.325418</td>\n",
              "      <td>-1.312253</td>\n",
              "      <td>0.590966</td>\n",
              "      <td>0.797195</td>\n",
              "      <td>-0.995879</td>\n",
              "      <td>-1.124606</td>\n",
              "      <td>-0.098990</td>\n",
              "      <td>0.024096</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.437325</td>\n",
              "      <td>-0.015533</td>\n",
              "      <td>-0.727710</td>\n",
              "      <td>1.027797</td>\n",
              "      <td>-1.424666</td>\n",
              "      <td>-0.476050</td>\n",
              "      <td>-0.090536</td>\n",
              "      <td>1.375026</td>\n",
              "      <td>0.701357</td>\n",
              "      <td>1.006041</td>\n",
              "      <td>...</td>\n",
              "      <td>1.208189</td>\n",
              "      <td>2.600642</td>\n",
              "      <td>0.077197</td>\n",
              "      <td>0.621890</td>\n",
              "      <td>1.319545</td>\n",
              "      <td>-1.578372</td>\n",
              "      <td>0.288048</td>\n",
              "      <td>-0.175495</td>\n",
              "      <td>-1.757541</td>\n",
              "      <td>-1.018862</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-2.172493</td>\n",
              "      <td>-0.883435</td>\n",
              "      <td>-0.986568</td>\n",
              "      <td>0.830565</td>\n",
              "      <td>-0.525877</td>\n",
              "      <td>0.518714</td>\n",
              "      <td>0.139243</td>\n",
              "      <td>1.200055</td>\n",
              "      <td>-2.134022</td>\n",
              "      <td>-0.128084</td>\n",
              "      <td>...</td>\n",
              "      <td>2.002734</td>\n",
              "      <td>2.586443</td>\n",
              "      <td>1.836435</td>\n",
              "      <td>-0.970768</td>\n",
              "      <td>2.494478</td>\n",
              "      <td>-0.942991</td>\n",
              "      <td>0.042452</td>\n",
              "      <td>0.403231</td>\n",
              "      <td>-0.119662</td>\n",
              "      <td>1.106133</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.543484</td>\n",
              "      <td>-0.625781</td>\n",
              "      <td>0.030770</td>\n",
              "      <td>-1.012685</td>\n",
              "      <td>-0.933100</td>\n",
              "      <td>-1.298510</td>\n",
              "      <td>-0.320477</td>\n",
              "      <td>1.359779</td>\n",
              "      <td>-1.723480</td>\n",
              "      <td>0.663527</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.395580</td>\n",
              "      <td>0.787761</td>\n",
              "      <td>1.333279</td>\n",
              "      <td>-0.708900</td>\n",
              "      <td>1.563627</td>\n",
              "      <td>0.989198</td>\n",
              "      <td>0.492953</td>\n",
              "      <td>-0.777206</td>\n",
              "      <td>0.715294</td>\n",
              "      <td>1.270499</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.277443</td>\n",
              "      <td>0.522612</td>\n",
              "      <td>-1.844515</td>\n",
              "      <td>0.934047</td>\n",
              "      <td>-0.796356</td>\n",
              "      <td>-0.239953</td>\n",
              "      <td>2.316574</td>\n",
              "      <td>1.749062</td>\n",
              "      <td>-1.337803</td>\n",
              "      <td>-1.877509</td>\n",
              "      <td>...</td>\n",
              "      <td>2.634269</td>\n",
              "      <td>-0.469678</td>\n",
              "      <td>2.793409</td>\n",
              "      <td>-0.382673</td>\n",
              "      <td>-1.181020</td>\n",
              "      <td>0.522740</td>\n",
              "      <td>0.010672</td>\n",
              "      <td>-1.501560</td>\n",
              "      <td>1.630964</td>\n",
              "      <td>1.042778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65349</th>\n",
              "      <td>0.337142</td>\n",
              "      <td>-1.077664</td>\n",
              "      <td>-0.455268</td>\n",
              "      <td>0.269491</td>\n",
              "      <td>-0.475726</td>\n",
              "      <td>1.610157</td>\n",
              "      <td>-0.713265</td>\n",
              "      <td>-0.539407</td>\n",
              "      <td>0.290899</td>\n",
              "      <td>-0.161023</td>\n",
              "      <td>...</td>\n",
              "      <td>0.266953</td>\n",
              "      <td>-0.025179</td>\n",
              "      <td>0.251291</td>\n",
              "      <td>-1.070246</td>\n",
              "      <td>1.224154</td>\n",
              "      <td>-0.457560</td>\n",
              "      <td>-0.865561</td>\n",
              "      <td>0.107556</td>\n",
              "      <td>-0.676872</td>\n",
              "      <td>-0.687075</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65350</th>\n",
              "      <td>-0.970615</td>\n",
              "      <td>0.679252</td>\n",
              "      <td>-0.475191</td>\n",
              "      <td>-0.760253</td>\n",
              "      <td>1.395637</td>\n",
              "      <td>-0.120007</td>\n",
              "      <td>-0.475762</td>\n",
              "      <td>0.390738</td>\n",
              "      <td>0.093672</td>\n",
              "      <td>-0.821998</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.267149</td>\n",
              "      <td>-0.131624</td>\n",
              "      <td>0.057884</td>\n",
              "      <td>-0.680531</td>\n",
              "      <td>-1.577589</td>\n",
              "      <td>0.535939</td>\n",
              "      <td>-0.596414</td>\n",
              "      <td>-0.688988</td>\n",
              "      <td>0.058833</td>\n",
              "      <td>0.240960</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65351</th>\n",
              "      <td>-0.430817</td>\n",
              "      <td>-0.320849</td>\n",
              "      <td>-0.056497</td>\n",
              "      <td>-1.180754</td>\n",
              "      <td>0.504585</td>\n",
              "      <td>2.236575</td>\n",
              "      <td>0.467192</td>\n",
              "      <td>-0.020317</td>\n",
              "      <td>-0.471456</td>\n",
              "      <td>-1.075086</td>\n",
              "      <td>...</td>\n",
              "      <td>0.032390</td>\n",
              "      <td>-0.110985</td>\n",
              "      <td>-0.175939</td>\n",
              "      <td>-1.883587</td>\n",
              "      <td>-0.894462</td>\n",
              "      <td>-0.968749</td>\n",
              "      <td>0.338284</td>\n",
              "      <td>-0.594822</td>\n",
              "      <td>0.738063</td>\n",
              "      <td>-1.228320</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65352</th>\n",
              "      <td>0.557895</td>\n",
              "      <td>-1.990042</td>\n",
              "      <td>0.589233</td>\n",
              "      <td>-1.006965</td>\n",
              "      <td>1.415527</td>\n",
              "      <td>0.446239</td>\n",
              "      <td>-0.436534</td>\n",
              "      <td>0.615573</td>\n",
              "      <td>-0.101743</td>\n",
              "      <td>-0.015296</td>\n",
              "      <td>...</td>\n",
              "      <td>0.155114</td>\n",
              "      <td>0.152983</td>\n",
              "      <td>-0.192486</td>\n",
              "      <td>-0.625859</td>\n",
              "      <td>-0.627880</td>\n",
              "      <td>-0.647677</td>\n",
              "      <td>-1.792593</td>\n",
              "      <td>0.189072</td>\n",
              "      <td>0.543923</td>\n",
              "      <td>-2.635595</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65353</th>\n",
              "      <td>-0.728911</td>\n",
              "      <td>-1.345793</td>\n",
              "      <td>0.046680</td>\n",
              "      <td>-0.250754</td>\n",
              "      <td>-0.241037</td>\n",
              "      <td>0.673405</td>\n",
              "      <td>-2.207394</td>\n",
              "      <td>-0.494322</td>\n",
              "      <td>0.861231</td>\n",
              "      <td>0.644561</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.765884</td>\n",
              "      <td>-0.322559</td>\n",
              "      <td>0.348290</td>\n",
              "      <td>0.895856</td>\n",
              "      <td>-0.282202</td>\n",
              "      <td>-0.043933</td>\n",
              "      <td>-0.535172</td>\n",
              "      <td>0.428676</td>\n",
              "      <td>0.214801</td>\n",
              "      <td>-1.291048</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>65354 rows Ã— 100 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             0         1         2         3         4         5         6   \\\n",
              "0      1.219739 -1.110067 -1.817891  0.435371 -1.260984 -0.823853  1.171997   \n",
              "1     -0.437325 -0.015533 -0.727710  1.027797 -1.424666 -0.476050 -0.090536   \n",
              "2     -2.172493 -0.883435 -0.986568  0.830565 -0.525877  0.518714  0.139243   \n",
              "3      0.543484 -0.625781  0.030770 -1.012685 -0.933100 -1.298510 -0.320477   \n",
              "4     -0.277443  0.522612 -1.844515  0.934047 -0.796356 -0.239953  2.316574   \n",
              "...         ...       ...       ...       ...       ...       ...       ...   \n",
              "65349  0.337142 -1.077664 -0.455268  0.269491 -0.475726  1.610157 -0.713265   \n",
              "65350 -0.970615  0.679252 -0.475191 -0.760253  1.395637 -0.120007 -0.475762   \n",
              "65351 -0.430817 -0.320849 -0.056497 -1.180754  0.504585  2.236575  0.467192   \n",
              "65352  0.557895 -1.990042  0.589233 -1.006965  1.415527  0.446239 -0.436534   \n",
              "65353 -0.728911 -1.345793  0.046680 -0.250754 -0.241037  0.673405 -2.207394   \n",
              "\n",
              "             7         8         9   ...        90        91        92  \\\n",
              "0      2.576343  1.515475 -1.234537  ... -0.291681  1.084419  1.325418   \n",
              "1      1.375026  0.701357  1.006041  ...  1.208189  2.600642  0.077197   \n",
              "2      1.200055 -2.134022 -0.128084  ...  2.002734  2.586443  1.836435   \n",
              "3      1.359779 -1.723480  0.663527  ... -0.395580  0.787761  1.333279   \n",
              "4      1.749062 -1.337803 -1.877509  ...  2.634269 -0.469678  2.793409   \n",
              "...         ...       ...       ...  ...       ...       ...       ...   \n",
              "65349 -0.539407  0.290899 -0.161023  ...  0.266953 -0.025179  0.251291   \n",
              "65350  0.390738  0.093672 -0.821998  ... -1.267149 -0.131624  0.057884   \n",
              "65351 -0.020317 -0.471456 -1.075086  ...  0.032390 -0.110985 -0.175939   \n",
              "65352  0.615573 -0.101743 -0.015296  ...  0.155114  0.152983 -0.192486   \n",
              "65353 -0.494322  0.861231  0.644561  ... -0.765884 -0.322559  0.348290   \n",
              "\n",
              "             93        94        95        96        97        98        99  \n",
              "0     -1.312253  0.590966  0.797195 -0.995879 -1.124606 -0.098990  0.024096  \n",
              "1      0.621890  1.319545 -1.578372  0.288048 -0.175495 -1.757541 -1.018862  \n",
              "2     -0.970768  2.494478 -0.942991  0.042452  0.403231 -0.119662  1.106133  \n",
              "3     -0.708900  1.563627  0.989198  0.492953 -0.777206  0.715294  1.270499  \n",
              "4     -0.382673 -1.181020  0.522740  0.010672 -1.501560  1.630964  1.042778  \n",
              "...         ...       ...       ...       ...       ...       ...       ...  \n",
              "65349 -1.070246  1.224154 -0.457560 -0.865561  0.107556 -0.676872 -0.687075  \n",
              "65350 -0.680531 -1.577589  0.535939 -0.596414 -0.688988  0.058833  0.240960  \n",
              "65351 -1.883587 -0.894462 -0.968749  0.338284 -0.594822  0.738063 -1.228320  \n",
              "65352 -0.625859 -0.627880 -0.647677 -1.792593  0.189072  0.543923 -2.635595  \n",
              "65353  0.895856 -0.282202 -0.043933 -0.535172  0.428676  0.214801 -1.291048  \n",
              "\n",
              "[65354 rows x 100 columns]"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "arr = [doc_model.dv[docs_dataset[\"text\"][i].tags] for i in docs_dataset.index]\n",
        "embeddings_dataset = pd.DataFrame(np.reshape(arr,(len(arr), 100)))\n",
        "embeddings_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "Sop_gw5PdYKj",
        "outputId": "489cc0f3-00c3-476a-c619-89a7dc34fe64"
      },
      "outputs": [],
      "source": [
        "embeddings_dataset.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XL1gXWWodYKj"
      },
      "source": [
        "#### Normalizar embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "embeddings_test_dataset[\"norm\"]=np.linalg.norm(embeddings_test_dataset, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5XdVRiYOdYKj",
        "outputId": "fdec5bf1-af94-4e9a-f178-6a6c7c01367d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0        13.226490\n",
              "1        11.933055\n",
              "2        11.891607\n",
              "3        12.467443\n",
              "4        14.188004\n",
              "           ...    \n",
              "65349     8.806262\n",
              "65350     9.364732\n",
              "65351     8.883014\n",
              "65352     9.615449\n",
              "65353     9.830458\n",
              "Name: norm, Length: 65354, dtype: float32"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "embeddings_dataset[\"norm\"]=np.linalg.norm(embeddings_dataset, axis=1)\n",
        "embeddings_dataset[\"norm\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "norm_embeddings_test_dataset = pd.DataFrame(np.apply_along_axis(lambda x: x / np.linalg.norm(x), axis=1, arr=embeddings_test_dataset))\n",
        "norm_embeddings_test_dataset[\"normalized_norm\"] = (embeddings_test_dataset['norm'] - embeddings_test_dataset['norm'].min()) / (embeddings_test_dataset['norm'].max() - embeddings_test_dataset['norm'].min())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "Y-ns5umfdYKj",
        "outputId": "e0e26dd1-7bc0-4a9e-d7c6-199d29518bec"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>92</th>\n",
              "      <th>93</th>\n",
              "      <th>94</th>\n",
              "      <th>95</th>\n",
              "      <th>96</th>\n",
              "      <th>97</th>\n",
              "      <th>98</th>\n",
              "      <th>99</th>\n",
              "      <th>100</th>\n",
              "      <th>normalized_norm</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>65354.000000</td>\n",
              "      <td>65354.000000</td>\n",
              "      <td>65354.000000</td>\n",
              "      <td>65354.000000</td>\n",
              "      <td>65354.000000</td>\n",
              "      <td>65354.000000</td>\n",
              "      <td>65354.000000</td>\n",
              "      <td>65354.000000</td>\n",
              "      <td>65354.000000</td>\n",
              "      <td>65354.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>65354.000000</td>\n",
              "      <td>65354.000000</td>\n",
              "      <td>65354.000000</td>\n",
              "      <td>65354.000000</td>\n",
              "      <td>65354.000000</td>\n",
              "      <td>65354.000000</td>\n",
              "      <td>65354.000000</td>\n",
              "      <td>65354.000000</td>\n",
              "      <td>6.535400e+04</td>\n",
              "      <td>65354.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>-0.021292</td>\n",
              "      <td>0.012930</td>\n",
              "      <td>0.012946</td>\n",
              "      <td>-0.003020</td>\n",
              "      <td>0.017714</td>\n",
              "      <td>-0.028594</td>\n",
              "      <td>-0.031155</td>\n",
              "      <td>-0.016679</td>\n",
              "      <td>0.005344</td>\n",
              "      <td>-0.011283</td>\n",
              "      <td>...</td>\n",
              "      <td>0.027360</td>\n",
              "      <td>-0.008509</td>\n",
              "      <td>0.017950</td>\n",
              "      <td>-0.003629</td>\n",
              "      <td>-0.021144</td>\n",
              "      <td>-0.026952</td>\n",
              "      <td>0.019090</td>\n",
              "      <td>-0.041961</td>\n",
              "      <td>7.071067e-01</td>\n",
              "      <td>0.319641</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.064276</td>\n",
              "      <td>0.062267</td>\n",
              "      <td>0.067974</td>\n",
              "      <td>0.063094</td>\n",
              "      <td>0.065342</td>\n",
              "      <td>0.061532</td>\n",
              "      <td>0.068641</td>\n",
              "      <td>0.064752</td>\n",
              "      <td>0.063186</td>\n",
              "      <td>0.066061</td>\n",
              "      <td>...</td>\n",
              "      <td>0.063927</td>\n",
              "      <td>0.064301</td>\n",
              "      <td>0.065723</td>\n",
              "      <td>0.064173</td>\n",
              "      <td>0.061830</td>\n",
              "      <td>0.062707</td>\n",
              "      <td>0.061773</td>\n",
              "      <td>0.062797</td>\n",
              "      <td>3.242300e-08</td>\n",
              "      <td>0.064466</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-0.277206</td>\n",
              "      <td>-0.259576</td>\n",
              "      <td>-0.281054</td>\n",
              "      <td>-0.249404</td>\n",
              "      <td>-0.243372</td>\n",
              "      <td>-0.262000</td>\n",
              "      <td>-0.289113</td>\n",
              "      <td>-0.288461</td>\n",
              "      <td>-0.255516</td>\n",
              "      <td>-0.277013</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.246769</td>\n",
              "      <td>-0.284033</td>\n",
              "      <td>-0.256151</td>\n",
              "      <td>-0.271852</td>\n",
              "      <td>-0.257155</td>\n",
              "      <td>-0.270161</td>\n",
              "      <td>-0.224737</td>\n",
              "      <td>-0.295688</td>\n",
              "      <td>7.071066e-01</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>-0.064951</td>\n",
              "      <td>-0.029371</td>\n",
              "      <td>-0.032896</td>\n",
              "      <td>-0.045173</td>\n",
              "      <td>-0.026396</td>\n",
              "      <td>-0.070695</td>\n",
              "      <td>-0.078437</td>\n",
              "      <td>-0.059780</td>\n",
              "      <td>-0.036829</td>\n",
              "      <td>-0.056120</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.015684</td>\n",
              "      <td>-0.052272</td>\n",
              "      <td>-0.026692</td>\n",
              "      <td>-0.047405</td>\n",
              "      <td>-0.063204</td>\n",
              "      <td>-0.070002</td>\n",
              "      <td>-0.022689</td>\n",
              "      <td>-0.085142</td>\n",
              "      <td>7.071068e-01</td>\n",
              "      <td>0.272576</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>-0.022187</td>\n",
              "      <td>0.013842</td>\n",
              "      <td>0.012695</td>\n",
              "      <td>-0.002226</td>\n",
              "      <td>0.018698</td>\n",
              "      <td>-0.029340</td>\n",
              "      <td>-0.031533</td>\n",
              "      <td>-0.016708</td>\n",
              "      <td>0.005758</td>\n",
              "      <td>-0.010497</td>\n",
              "      <td>...</td>\n",
              "      <td>0.027355</td>\n",
              "      <td>-0.008182</td>\n",
              "      <td>0.017452</td>\n",
              "      <td>-0.003292</td>\n",
              "      <td>-0.021861</td>\n",
              "      <td>-0.027813</td>\n",
              "      <td>0.018650</td>\n",
              "      <td>-0.042775</td>\n",
              "      <td>7.071068e-01</td>\n",
              "      <td>0.317468</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.021894</td>\n",
              "      <td>0.055866</td>\n",
              "      <td>0.059091</td>\n",
              "      <td>0.039620</td>\n",
              "      <td>0.062732</td>\n",
              "      <td>0.012495</td>\n",
              "      <td>0.015680</td>\n",
              "      <td>0.026144</td>\n",
              "      <td>0.048333</td>\n",
              "      <td>0.033978</td>\n",
              "      <td>...</td>\n",
              "      <td>0.071008</td>\n",
              "      <td>0.035027</td>\n",
              "      <td>0.062489</td>\n",
              "      <td>0.040278</td>\n",
              "      <td>0.020389</td>\n",
              "      <td>0.015408</td>\n",
              "      <td>0.060927</td>\n",
              "      <td>0.000563</td>\n",
              "      <td>7.071068e-01</td>\n",
              "      <td>0.362039</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>0.284890</td>\n",
              "      <td>0.248083</td>\n",
              "      <td>0.271072</td>\n",
              "      <td>0.243227</td>\n",
              "      <td>0.291685</td>\n",
              "      <td>0.232238</td>\n",
              "      <td>0.240662</td>\n",
              "      <td>0.247933</td>\n",
              "      <td>0.262753</td>\n",
              "      <td>0.239804</td>\n",
              "      <td>...</td>\n",
              "      <td>0.332902</td>\n",
              "      <td>0.259530</td>\n",
              "      <td>0.284886</td>\n",
              "      <td>0.256541</td>\n",
              "      <td>0.261595</td>\n",
              "      <td>0.219104</td>\n",
              "      <td>0.268850</td>\n",
              "      <td>0.255575</td>\n",
              "      <td>7.071069e-01</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows Ã— 102 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                  0             1             2             3             4  \\\n",
              "count  65354.000000  65354.000000  65354.000000  65354.000000  65354.000000   \n",
              "mean      -0.021292      0.012930      0.012946     -0.003020      0.017714   \n",
              "std        0.064276      0.062267      0.067974      0.063094      0.065342   \n",
              "min       -0.277206     -0.259576     -0.281054     -0.249404     -0.243372   \n",
              "25%       -0.064951     -0.029371     -0.032896     -0.045173     -0.026396   \n",
              "50%       -0.022187      0.013842      0.012695     -0.002226      0.018698   \n",
              "75%        0.021894      0.055866      0.059091      0.039620      0.062732   \n",
              "max        0.284890      0.248083      0.271072      0.243227      0.291685   \n",
              "\n",
              "                  5             6             7             8             9  \\\n",
              "count  65354.000000  65354.000000  65354.000000  65354.000000  65354.000000   \n",
              "mean      -0.028594     -0.031155     -0.016679      0.005344     -0.011283   \n",
              "std        0.061532      0.068641      0.064752      0.063186      0.066061   \n",
              "min       -0.262000     -0.289113     -0.288461     -0.255516     -0.277013   \n",
              "25%       -0.070695     -0.078437     -0.059780     -0.036829     -0.056120   \n",
              "50%       -0.029340     -0.031533     -0.016708      0.005758     -0.010497   \n",
              "75%        0.012495      0.015680      0.026144      0.048333      0.033978   \n",
              "max        0.232238      0.240662      0.247933      0.262753      0.239804   \n",
              "\n",
              "       ...            92            93            94            95  \\\n",
              "count  ...  65354.000000  65354.000000  65354.000000  65354.000000   \n",
              "mean   ...      0.027360     -0.008509      0.017950     -0.003629   \n",
              "std    ...      0.063927      0.064301      0.065723      0.064173   \n",
              "min    ...     -0.246769     -0.284033     -0.256151     -0.271852   \n",
              "25%    ...     -0.015684     -0.052272     -0.026692     -0.047405   \n",
              "50%    ...      0.027355     -0.008182      0.017452     -0.003292   \n",
              "75%    ...      0.071008      0.035027      0.062489      0.040278   \n",
              "max    ...      0.332902      0.259530      0.284886      0.256541   \n",
              "\n",
              "                 96            97            98            99           100  \\\n",
              "count  65354.000000  65354.000000  65354.000000  65354.000000  6.535400e+04   \n",
              "mean      -0.021144     -0.026952      0.019090     -0.041961  7.071067e-01   \n",
              "std        0.061830      0.062707      0.061773      0.062797  3.242300e-08   \n",
              "min       -0.257155     -0.270161     -0.224737     -0.295688  7.071066e-01   \n",
              "25%       -0.063204     -0.070002     -0.022689     -0.085142  7.071068e-01   \n",
              "50%       -0.021861     -0.027813      0.018650     -0.042775  7.071068e-01   \n",
              "75%        0.020389      0.015408      0.060927      0.000563  7.071068e-01   \n",
              "max        0.261595      0.219104      0.268850      0.255575  7.071069e-01   \n",
              "\n",
              "       normalized_norm  \n",
              "count     65354.000000  \n",
              "mean          0.319641  \n",
              "std           0.064466  \n",
              "min           0.000000  \n",
              "25%           0.272576  \n",
              "50%           0.317468  \n",
              "75%           0.362039  \n",
              "max           1.000000  \n",
              "\n",
              "[8 rows x 102 columns]"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "norm_embeddings_dataset = pd.DataFrame(np.apply_along_axis(lambda x: x / np.linalg.norm(x), axis=1, arr=embeddings_dataset))\n",
        "norm_embeddings_dataset[\"normalized_norm\"] = (embeddings_dataset['norm'] - embeddings_dataset['norm'].min()) / (embeddings_dataset['norm'].max() - embeddings_dataset['norm'].min())\n",
        "norm_embeddings_dataset.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "norm_embeddings_test_dataset = norm_embeddings_test_dataset.drop([100],axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "2jUZ8xrgdYKj"
      },
      "outputs": [],
      "source": [
        "norm_embeddings_dataset = norm_embeddings_dataset.drop([100],axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>prompt_id</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0000aaaa</td>\n",
              "      <td>2</td>\n",
              "      <td>([Ä aaa, Ä b, b, b, Ä c, cc, .], [0000aaaa])</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1111bbbb</td>\n",
              "      <td>3</td>\n",
              "      <td>([Ä b, b, b, Ä c, cc, Ä d, dd, .], [1111bbbb])</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2222cccc</td>\n",
              "      <td>4</td>\n",
              "      <td>([Ä c, cc, Ä d, dd, Ä e, ee, .], [2222cccc])</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         id  prompt_id                                         text\n",
              "0  0000aaaa          2    ([Ä aaa, Ä b, b, b, Ä c, cc, .], [0000aaaa])\n",
              "1  1111bbbb          3  ([Ä b, b, b, Ä c, cc, Ä d, dd, .], [1111bbbb])\n",
              "2  2222cccc          4    ([Ä c, cc, Ä d, dd, Ä e, ee, .], [2222cccc])"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "doc_test_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>91</th>\n",
              "      <th>92</th>\n",
              "      <th>93</th>\n",
              "      <th>94</th>\n",
              "      <th>95</th>\n",
              "      <th>96</th>\n",
              "      <th>97</th>\n",
              "      <th>98</th>\n",
              "      <th>99</th>\n",
              "      <th>normalized_norm</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.040128</td>\n",
              "      <td>0.015641</td>\n",
              "      <td>0.008331</td>\n",
              "      <td>-0.012491</td>\n",
              "      <td>0.044065</td>\n",
              "      <td>-0.040452</td>\n",
              "      <td>-0.047977</td>\n",
              "      <td>-0.074252</td>\n",
              "      <td>0.028167</td>\n",
              "      <td>-0.015179</td>\n",
              "      <td>...</td>\n",
              "      <td>0.124750</td>\n",
              "      <td>0.072305</td>\n",
              "      <td>-0.050204</td>\n",
              "      <td>0.025509</td>\n",
              "      <td>0.016998</td>\n",
              "      <td>0.012296</td>\n",
              "      <td>-0.055793</td>\n",
              "      <td>0.041121</td>\n",
              "      <td>-0.087877</td>\n",
              "      <td>0.742083</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.000625</td>\n",
              "      <td>0.039342</td>\n",
              "      <td>0.020408</td>\n",
              "      <td>-0.018070</td>\n",
              "      <td>0.034246</td>\n",
              "      <td>-0.013891</td>\n",
              "      <td>-0.035015</td>\n",
              "      <td>-0.065681</td>\n",
              "      <td>0.059665</td>\n",
              "      <td>0.003054</td>\n",
              "      <td>...</td>\n",
              "      <td>0.139950</td>\n",
              "      <td>0.044903</td>\n",
              "      <td>-0.053113</td>\n",
              "      <td>0.004436</td>\n",
              "      <td>0.011252</td>\n",
              "      <td>-0.005137</td>\n",
              "      <td>-0.061565</td>\n",
              "      <td>0.039369</td>\n",
              "      <td>-0.090179</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.024857</td>\n",
              "      <td>0.005393</td>\n",
              "      <td>0.005911</td>\n",
              "      <td>-0.023451</td>\n",
              "      <td>0.067951</td>\n",
              "      <td>-0.009769</td>\n",
              "      <td>-0.019388</td>\n",
              "      <td>-0.036204</td>\n",
              "      <td>0.014573</td>\n",
              "      <td>-0.037588</td>\n",
              "      <td>...</td>\n",
              "      <td>0.108641</td>\n",
              "      <td>0.048119</td>\n",
              "      <td>-0.025421</td>\n",
              "      <td>-0.002160</td>\n",
              "      <td>0.007503</td>\n",
              "      <td>0.007232</td>\n",
              "      <td>-0.041582</td>\n",
              "      <td>0.040649</td>\n",
              "      <td>-0.070331</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3 rows Ã— 101 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          0         1         2         3         4         5         6  \\\n",
              "0 -0.040128  0.015641  0.008331 -0.012491  0.044065 -0.040452 -0.047977   \n",
              "1 -0.000625  0.039342  0.020408 -0.018070  0.034246 -0.013891 -0.035015   \n",
              "2 -0.024857  0.005393  0.005911 -0.023451  0.067951 -0.009769 -0.019388   \n",
              "\n",
              "          7         8         9  ...        91        92        93        94  \\\n",
              "0 -0.074252  0.028167 -0.015179  ...  0.124750  0.072305 -0.050204  0.025509   \n",
              "1 -0.065681  0.059665  0.003054  ...  0.139950  0.044903 -0.053113  0.004436   \n",
              "2 -0.036204  0.014573 -0.037588  ...  0.108641  0.048119 -0.025421 -0.002160   \n",
              "\n",
              "         95        96        97        98        99  normalized_norm  \n",
              "0  0.016998  0.012296 -0.055793  0.041121 -0.087877         0.742083  \n",
              "1  0.011252 -0.005137 -0.061565  0.039369 -0.090179         1.000000  \n",
              "2  0.007503  0.007232 -0.041582  0.040649 -0.070331         0.000000  \n",
              "\n",
              "[3 rows x 101 columns]"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "norm_embeddings_test_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pre_processed_test_data = pd.concat([doc_test_dataset,norm_embeddings_test_dataset],axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 826
        },
        "id": "MwmoLIkHdYKk",
        "outputId": "ce49eba2-4bc9-4547-b019-5ce71a71e360"
      },
      "outputs": [],
      "source": [
        "pre_processed_data = pd.concat([docs_dataset,norm_embeddings_dataset],axis=1)\n",
        "#pre_processed_data = pd.concat([docs_dataset,embeddings_dataset],axis=1)\n",
        "pre_processed_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ok4YnFIkdYKk"
      },
      "source": [
        "### Inferred Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5LK85lV3dYKk"
      },
      "outputs": [],
      "source": [
        "def features(dataset):\n",
        "    token_count=dataset[\"text\"].apply(lambda x: len(x))\n",
        "    sentence_count = []\n",
        "    punctuation_count = []\n",
        "    apostrofees_count = []\n",
        "    unk_count = []\n",
        "    for doc in dataset[\"text\"]:\n",
        "        unk = 0\n",
        "        dot = 0\n",
        "        punctuation = 0\n",
        "        apostrofees = 0\n",
        "        for token in doc.words:\n",
        "            if(token.endswith(\".\")):\n",
        "                dot+=1\n",
        "                punctuation+=1\n",
        "            elif(token.endswith(\",\") or token.endswith(\"?\") or token.endswith(\"!\")):\n",
        "                punctuation+=1\n",
        "            elif(token.count(\"'\")>0):\n",
        "                    apostrofees+=token.count(\"'\")\n",
        "            elif(token==\"[UNK]\"):\n",
        "                unk+=1\n",
        "        sentence_count.append(dot)\n",
        "        punctuation_count.append(punctuation)\n",
        "        apostrofees_count.append(apostrofees)\n",
        "        unk_count.append(unk)\n",
        "    df = pd.DataFrame(\n",
        "        columns=[\"token_num\",\"sent_num\",\"punct_sym\",\"apostrof_sym\",\"unk_num\"]\n",
        "    )\n",
        "    df[\"token_num\"]=token_count\n",
        "    df[\"sent_num\"]=sentence_count\n",
        "    df[\"punct_sym\"]=punctuation_count\n",
        "    df[\"apostrof_sym\"]=apostrofees_count\n",
        "    df[\"unk_num\"]=unk_count\n",
        "    return df\n",
        "\n",
        "train_features = features(pre_processed_data)\n",
        "test_features = features(pre_processed_test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "for col in test_features.columns:\n",
        "    if(test_features[col].max()>0):\n",
        "        test_features[col] = test_features[col] / np.linalg.norm(test_features[col])\n",
        "\n",
        "for col in train_features.columns:\n",
        "    if(train_features[col].max()>0):\n",
        "        train_features[col] = train_features[col]/np.linalg.norm(train_features[col])\n",
        "\n",
        "test_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pre_processed_data=pd.concat([pre_processed_data,train_features],axis=1).drop(\"text\",axis=1)\n",
        "pre_processed_test_data=pd.concat([pre_processed_test_data,test_features],axis=1).drop(\"text\",axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "KKJrJzEWdYKl",
        "outputId": "50ad4a58-1b24-408d-db60-c5bad8697938"
      },
      "outputs": [],
      "source": [
        "pre_processed_data.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pre_processed_data.to_csv(\"../../data/pre_process_train.csv\")\n",
        "pre_processed_test_data.to_csv(\"../../data/pre_process_test.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pre_processed_data=pd.read_csv(\"../../data/pre_process_train.csv\")\n",
        "pre_processed_test_data=pd.read_csv(\"../../data/pre_process_test.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pboIBijydYKl"
      },
      "source": [
        "## Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sieb_gK4dYKl"
      },
      "outputs": [],
      "source": [
        "def downsampling(X_train,y_train,rand_state,ratio):\n",
        "    # Concatenate X_train and y_train for ease of downsampling\n",
        "    train_data = pd.concat([X_train, y_train], axis=1)\n",
        "\n",
        "    # Identify the class with the majority of instances\n",
        "    majority_class = train_data[y_train.name].value_counts().idxmax()\n",
        "\n",
        "    # Separate instances of each class\n",
        "    majority_class_data = train_data[train_data[y_train.name] == majority_class]\n",
        "    minority_class_data = train_data[train_data[y_train.name] != majority_class]\n",
        "\n",
        "\n",
        "    currRatio = len(majority_class_data) / len(minority_class_data)\n",
        "    if(currRatio<=ratio):\n",
        "        raise ValueError(f\"El ratio de entrada debe ser menor al ratio actual.r={currRatio}\")\n",
        "\n",
        "\n",
        "    # Downsample the majority class to match the number of instances in the minority class\n",
        "    downsampled_majority_class_data = resample(\n",
        "        majority_class_data,\n",
        "        replace=False,\n",
        "        n_samples=math.floor(ratio*len(minority_class_data)),\n",
        "        random_state=rand_state\n",
        "    )\n",
        "\n",
        "    # Combine the downsampled majority class with the minority class\n",
        "    downsampled_train_data = pd.concat([downsampled_majority_class_data, minority_class_data])\n",
        "\n",
        "    # Shuffle the data to avoid any order-based patterns\n",
        "    downsampled_train_data = downsampled_train_data.sample(frac=1, random_state=rand_state)\n",
        "\n",
        "    # Separate X_train and y_train after downsampling\n",
        "    X_train_downsampled = downsampled_train_data.drop(columns=[y_train.name])\n",
        "    y_train_downsampled = downsampled_train_data[y_train.name]\n",
        "\n",
        "    return X_train_downsampled, y_train_downsampled"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Arquitecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "input = keras.Input(shape=(pre_processed_data.shape[1]-2,))\n",
        "x = keras.layers.Dense(pre_processed_data.shape[1]-2,activation=\"relu\")(input)\n",
        "x = keras.layers.Dense(100,activation=\"relu\")(input)\n",
        "output = keras.layers.Dense(1,activation=\"sigmoid\")(x)\n",
        "\n",
        "NNmodel = keras.Model(input,output)\n",
        "\n",
        "NNmodel.compile(optimizer='adam',\n",
        "               loss=keras.losses.BinaryCrossentropy(),\n",
        "               metrics=[keras.metrics.AUC()])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "eE-YSa9jdYKm",
        "outputId": "1017a0f1-e1de-49da-ed83-603324aa1644"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "rand_state= random.randint(0,1000)\n",
        "#NN training with 10-fold cross-validation stratified with random under-sampling technic for imbalanced data\n",
        "X = pre_processed_data.drop([\"id\",\"generated\"],axis=1)\n",
        "Y = pre_processed_data[\"generated\"]\n",
        "folds = StratifiedKFold(10,shuffle=True,random_state=rand_state)\n",
        "for fold, (train_index, val_index) in enumerate(folds.split(X,Y)):\n",
        "    X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
        "    y_train, y_val = Y.iloc[train_index], Y.iloc[val_index]\n",
        "\n",
        "    X_train_dwns, y_train_dwns = downsampling(X_train,y_train,rand_state,ratio=20)\n",
        "\n",
        "    #print(f\"Fold {fold + 1}: Train {len(train_index)} samples, Validation {len(val_index)} samples\")\n",
        "    #print(f\"TRAIN:({y_train[y_train==0].size}:{y_train[y_train==1].size})\")\n",
        "    print(f\"DOWNSAMPLED:({y_train_dwns[y_train_dwns==0].size}:{y_train_dwns[y_train_dwns==1].size})\")\n",
        "    #print(f\"VAL:({y_val[y_val==0].size}:{y_val[y_val==1].size})\")\n",
        "\n",
        "    NNmodel.fit(X_train_dwns,\n",
        "                y_train_dwns,\n",
        "                validation_data=(X_val,y_val),\n",
        "                epochs=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ROCcurves(NNmodel,X,Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ub2SWyaC9uL2",
        "outputId": "d63e26ff-e443-4621-9757-f9444e0fdfa6"
      },
      "outputs": [],
      "source": [
        "pred = list(map(lambda pred : 1 if pred > 0.5 else 0,NNmodel.predict(x=X)))\n",
        "display = ConfusionMatrixDisplay(confusion_matrix(pred,Y),display_labels=[\"True\",\"False\"])\n",
        "display.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o5dVLLxVyjOg",
        "outputId": "4d54fa2d-90ac-45bf-fddb-16e7cebe5806"
      },
      "outputs": [],
      "source": [
        "NNmodel.predict(x=pd.DataFrame(X.iloc[1385]).transpose())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RY59QZYXdYKm"
      },
      "source": [
        "## Model test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_test = pre_processed_test_data.drop([\"id\"],axis=1)\n",
        "submition = pd.DataFrame()\n",
        "submition[\"id\"]=pre_processed_test_data[\"id\"].to_numpy()\n",
        "submition[\"generated\"]=NNmodel.predict(x=X_test)\n",
        "submition[\"generated\"] = submition[\"generated\"].apply(lambda x : round(x,4))\n",
        "submition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "submition.to_csv(\"../../data/submission.csv\",index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Embeddings ploting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.scatter(x=pre_processed_data[pre_processed_data[\"generated\"]==0][20],\n",
        "            y=pre_processed_data[pre_processed_data[\"generated\"]==0][40])\n",
        "plt.scatter(x=pre_processed_data[pre_processed_data[\"generated\"]==1][20],\n",
        "            y=pre_processed_data[pre_processed_data[\"generated\"]==1][40])\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
