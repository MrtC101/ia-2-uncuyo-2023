{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM - Detect AI Generated Text\n",
    "# PREDICTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from gensim.models import doc2vec\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "\n",
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inferred Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features(dataset):\n",
    "    token_count=dataset[\"text\"].apply(lambda x: len(x))\n",
    "    sentence_count = []\n",
    "    punctuation_count = []\n",
    "    apostrofees_count = []\n",
    "    unk_count = []\n",
    "    for doc in dataset[\"text\"]:\n",
    "        unk = 0\n",
    "        dot = 0\n",
    "        punctuation = 0\n",
    "        apostrofees = 0\n",
    "        for token in doc:\n",
    "            if(token.endswith(\".\")):\n",
    "                dot+=1\n",
    "                punctuation+=1\n",
    "            elif(token.endswith(\",\") or token.endswith(\"?\") or token.endswith(\"!\")):\n",
    "                punctuation+=1\n",
    "            elif(token.count(\"'\")>0):\n",
    "                    apostrofees+=token.count(\"'\")\n",
    "            elif(token==\"[UNK]\"):\n",
    "                unk+=1\n",
    "        sentence_count.append(dot)\n",
    "        punctuation_count.append(punctuation)\n",
    "        apostrofees_count.append(apostrofees)\n",
    "        unk_count.append(unk)\n",
    "    df = pd.DataFrame(\n",
    "        columns=[\"token_num\",\"sent_num\",\"punct_sym\",\"apostrof_sym\",\"unk_num\"]\n",
    "    )\n",
    "    df[\"token_num\"]=token_count\n",
    "    df[\"sent_num\"]=sentence_count\n",
    "    df[\"punct_sym\"]=punctuation_count\n",
    "    df[\"apostrof_sym\"]=apostrofees_count\n",
    "    df[\"unk_num\"]=unk_count\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = pd.read_csv(\"../data/test_essays.csv\")\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained(\"../data/byte_pair_tokenizer/\")\n",
    "doc_model = doc2vec.Doc2Vec.load(\"../data/embedding_model/docModel.bin\")\n",
    "model = keras.models.load_model(\"../data/CNN/weights.h5\")\n",
    "subPath = \"../data/CNN/submission.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load tokenizer\n",
    "tokenized_test = test_dataset;\n",
    "tokenized_test[\"text\"] = test_dataset[\"text\"].apply(lambda x : tokenizer.tokenize(text=x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.579811</td>\n",
       "      <td>-0.023181</td>\n",
       "      <td>0.105455</td>\n",
       "      <td>0.964687</td>\n",
       "      <td>-1.137239</td>\n",
       "      <td>-0.284674</td>\n",
       "      <td>0.798672</td>\n",
       "      <td>1.683975</td>\n",
       "      <td>-1.452440</td>\n",
       "      <td>-1.469087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021805</td>\n",
       "      <td>-0.369931</td>\n",
       "      <td>0.773667</td>\n",
       "      <td>-0.063291</td>\n",
       "      <td>-0.743866</td>\n",
       "      <td>0.615434</td>\n",
       "      <td>0.412717</td>\n",
       "      <td>-0.246424</td>\n",
       "      <td>2.069485</td>\n",
       "      <td>-1.535682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.846651</td>\n",
       "      <td>-0.690581</td>\n",
       "      <td>-0.383330</td>\n",
       "      <td>0.381186</td>\n",
       "      <td>-0.338441</td>\n",
       "      <td>-0.331480</td>\n",
       "      <td>0.590804</td>\n",
       "      <td>0.894206</td>\n",
       "      <td>-1.246327</td>\n",
       "      <td>-0.346884</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.351556</td>\n",
       "      <td>0.513875</td>\n",
       "      <td>0.779376</td>\n",
       "      <td>0.465845</td>\n",
       "      <td>-0.495945</td>\n",
       "      <td>0.578675</td>\n",
       "      <td>0.211442</td>\n",
       "      <td>-0.000358</td>\n",
       "      <td>2.048722</td>\n",
       "      <td>-1.408140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.336258</td>\n",
       "      <td>-0.404491</td>\n",
       "      <td>-0.713487</td>\n",
       "      <td>1.189348</td>\n",
       "      <td>-0.542389</td>\n",
       "      <td>-0.520110</td>\n",
       "      <td>0.331135</td>\n",
       "      <td>0.673923</td>\n",
       "      <td>-0.803540</td>\n",
       "      <td>-0.524820</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.113739</td>\n",
       "      <td>0.120349</td>\n",
       "      <td>0.947649</td>\n",
       "      <td>0.414408</td>\n",
       "      <td>-0.583618</td>\n",
       "      <td>0.262747</td>\n",
       "      <td>-0.127890</td>\n",
       "      <td>-0.430329</td>\n",
       "      <td>1.464094</td>\n",
       "      <td>-0.798821</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0 -0.579811 -0.023181  0.105455  0.964687 -1.137239 -0.284674  0.798672   \n",
       "1 -0.846651 -0.690581 -0.383330  0.381186 -0.338441 -0.331480  0.590804   \n",
       "2 -1.336258 -0.404491 -0.713487  1.189348 -0.542389 -0.520110  0.331135   \n",
       "\n",
       "         7         8         9   ...        90        91        92        93  \\\n",
       "0  1.683975 -1.452440 -1.469087  ...  0.021805 -0.369931  0.773667 -0.063291   \n",
       "1  0.894206 -1.246327 -0.346884  ... -0.351556  0.513875  0.779376  0.465845   \n",
       "2  0.673923 -0.803540 -0.524820  ... -0.113739  0.120349  0.947649  0.414408   \n",
       "\n",
       "         94        95        96        97        98        99  \n",
       "0 -0.743866  0.615434  0.412717 -0.246424  2.069485 -1.535682  \n",
       "1 -0.495945  0.578675  0.211442 -0.000358  2.048722 -1.408140  \n",
       "2 -0.583618  0.262747 -0.127890 -0.430329  1.464094 -0.798821  \n",
       "\n",
       "[3 rows x 100 columns]"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load embeddings model\n",
    "embeddings_matrix = [doc_model.infer_vector(tokenList,epochs=400) for tokenList in tokenized_test[\"text\"]]\n",
    "embeddings_test_dataset = pd.DataFrame(embeddings_matrix)\n",
    "embeddings_test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalizado de embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>text</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>...</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>normalized_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000aaaa</td>\n",
       "      <td>2</td>\n",
       "      <td>[Ġaaa, Ġb, b, b, Ġc, cc, .]</td>\n",
       "      <td>-0.040339</td>\n",
       "      <td>-0.001613</td>\n",
       "      <td>0.007337</td>\n",
       "      <td>0.067117</td>\n",
       "      <td>-0.079122</td>\n",
       "      <td>-0.019806</td>\n",
       "      <td>0.055566</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025737</td>\n",
       "      <td>0.053827</td>\n",
       "      <td>-0.004403</td>\n",
       "      <td>-0.051753</td>\n",
       "      <td>0.042818</td>\n",
       "      <td>0.028714</td>\n",
       "      <td>-0.017145</td>\n",
       "      <td>0.143981</td>\n",
       "      <td>-0.106843</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1111bbbb</td>\n",
       "      <td>3</td>\n",
       "      <td>[Ġb, b, b, Ġc, cc, Ġd, dd, .]</td>\n",
       "      <td>-0.087266</td>\n",
       "      <td>-0.071179</td>\n",
       "      <td>-0.039510</td>\n",
       "      <td>0.039290</td>\n",
       "      <td>-0.034884</td>\n",
       "      <td>-0.034166</td>\n",
       "      <td>0.060895</td>\n",
       "      <td>...</td>\n",
       "      <td>0.052966</td>\n",
       "      <td>0.080332</td>\n",
       "      <td>0.048015</td>\n",
       "      <td>-0.051118</td>\n",
       "      <td>0.059645</td>\n",
       "      <td>0.021794</td>\n",
       "      <td>-0.000037</td>\n",
       "      <td>0.211165</td>\n",
       "      <td>-0.145139</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2222cccc</td>\n",
       "      <td>4</td>\n",
       "      <td>[Ġc, cc, Ġd, dd, Ġe, ee, .]</td>\n",
       "      <td>-0.136463</td>\n",
       "      <td>-0.041308</td>\n",
       "      <td>-0.072864</td>\n",
       "      <td>0.121460</td>\n",
       "      <td>-0.055390</td>\n",
       "      <td>-0.053115</td>\n",
       "      <td>0.033817</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012290</td>\n",
       "      <td>0.096777</td>\n",
       "      <td>0.042321</td>\n",
       "      <td>-0.059601</td>\n",
       "      <td>0.026833</td>\n",
       "      <td>-0.013061</td>\n",
       "      <td>-0.043947</td>\n",
       "      <td>0.149518</td>\n",
       "      <td>-0.081578</td>\n",
       "      <td>0.019292</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 104 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  prompt_id                           text         0         1  \\\n",
       "0  0000aaaa          2    [Ġaaa, Ġb, b, b, Ġc, cc, .] -0.040339 -0.001613   \n",
       "1  1111bbbb          3  [Ġb, b, b, Ġc, cc, Ġd, dd, .] -0.087266 -0.071179   \n",
       "2  2222cccc          4    [Ġc, cc, Ġd, dd, Ġe, ee, .] -0.136463 -0.041308   \n",
       "\n",
       "          2         3         4         5         6  ...        91        92  \\\n",
       "0  0.007337  0.067117 -0.079122 -0.019806  0.055566  ... -0.025737  0.053827   \n",
       "1 -0.039510  0.039290 -0.034884 -0.034166  0.060895  ...  0.052966  0.080332   \n",
       "2 -0.072864  0.121460 -0.055390 -0.053115  0.033817  ...  0.012290  0.096777   \n",
       "\n",
       "         93        94        95        96        97        98        99  \\\n",
       "0 -0.004403 -0.051753  0.042818  0.028714 -0.017145  0.143981 -0.106843   \n",
       "1  0.048015 -0.051118  0.059645  0.021794 -0.000037  0.211165 -0.145139   \n",
       "2  0.042321 -0.059601  0.026833 -0.013061 -0.043947  0.149518 -0.081578   \n",
       "\n",
       "   normalized_norm  \n",
       "0         1.000000  \n",
       "1         0.000000  \n",
       "2         0.019292  \n",
       "\n",
       "[3 rows x 104 columns]"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_test_dataset[\"norm\"]=np.linalg.norm(embeddings_test_dataset, axis=1)\n",
    "norm_embeddings_test_dataset = pd.DataFrame(np.apply_along_axis(lambda x: x / np.linalg.norm(x), axis=1, arr=embeddings_test_dataset))\n",
    "norm_embeddings_test_dataset[\"normalized_norm\"] = (embeddings_test_dataset['norm'] - embeddings_test_dataset['norm'].min()) / (embeddings_test_dataset['norm'].max() - embeddings_test_dataset['norm'].min())\n",
    "norm_embeddings_test_dataset = norm_embeddings_test_dataset.drop([100],axis=1)\n",
    "pre_processed_test_data = pd.concat([tokenized_test,norm_embeddings_test_dataset],axis=1)\n",
    "pre_processed_test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature inferring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = features(pre_processed_test_data)\n",
    "for col in test_features.columns:\n",
    "    if(test_features[col].max()>0):\n",
    "        test_features[col] = test_features[col] / np.linalg.norm(test_features[col])\n",
    "pre_processed_test_data=pd.concat([pre_processed_test_data,test_features],axis=1).drop(\"text\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>normalized_norm</th>\n",
       "      <th>token_num</th>\n",
       "      <th>sent_num</th>\n",
       "      <th>punct_sym</th>\n",
       "      <th>apostrof_sym</th>\n",
       "      <th>unk_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000aaaa</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.040339</td>\n",
       "      <td>-0.001613</td>\n",
       "      <td>0.007337</td>\n",
       "      <td>0.067117</td>\n",
       "      <td>-0.079122</td>\n",
       "      <td>-0.019806</td>\n",
       "      <td>0.055566</td>\n",
       "      <td>0.117160</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028714</td>\n",
       "      <td>-0.017145</td>\n",
       "      <td>0.143981</td>\n",
       "      <td>-0.106843</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.549972</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1111bbbb</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.087266</td>\n",
       "      <td>-0.071179</td>\n",
       "      <td>-0.039510</td>\n",
       "      <td>0.039290</td>\n",
       "      <td>-0.034884</td>\n",
       "      <td>-0.034166</td>\n",
       "      <td>0.060895</td>\n",
       "      <td>0.092167</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021794</td>\n",
       "      <td>-0.000037</td>\n",
       "      <td>0.211165</td>\n",
       "      <td>-0.145139</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.628539</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2222cccc</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.136463</td>\n",
       "      <td>-0.041308</td>\n",
       "      <td>-0.072864</td>\n",
       "      <td>0.121460</td>\n",
       "      <td>-0.055390</td>\n",
       "      <td>-0.053115</td>\n",
       "      <td>0.033817</td>\n",
       "      <td>0.068823</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.013061</td>\n",
       "      <td>-0.043947</td>\n",
       "      <td>0.149518</td>\n",
       "      <td>-0.081578</td>\n",
       "      <td>0.019292</td>\n",
       "      <td>0.549972</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 108 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  prompt_id         0         1         2         3         4  \\\n",
       "0  0000aaaa          2 -0.040339 -0.001613  0.007337  0.067117 -0.079122   \n",
       "1  1111bbbb          3 -0.087266 -0.071179 -0.039510  0.039290 -0.034884   \n",
       "2  2222cccc          4 -0.136463 -0.041308 -0.072864  0.121460 -0.055390   \n",
       "\n",
       "          5         6         7  ...        96        97        98        99  \\\n",
       "0 -0.019806  0.055566  0.117160  ...  0.028714 -0.017145  0.143981 -0.106843   \n",
       "1 -0.034166  0.060895  0.092167  ...  0.021794 -0.000037  0.211165 -0.145139   \n",
       "2 -0.053115  0.033817  0.068823  ... -0.013061 -0.043947  0.149518 -0.081578   \n",
       "\n",
       "   normalized_norm  token_num  sent_num  punct_sym  apostrof_sym  unk_num  \n",
       "0         1.000000   0.549972   0.57735    0.57735             0        0  \n",
       "1         0.000000   0.628539   0.57735    0.57735             0        0  \n",
       "2         0.019292   0.549972   0.57735    0.57735             0        0  \n",
       "\n",
       "[3 rows x 108 columns]"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_processed_test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 168ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [1.],\n",
       "       [1.]], dtype=float32)"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load model\n",
    "X_test = pre_processed_test_data.drop([\"id\"],axis=1)\n",
    "pred = model.predict(x=X_test)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>generated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000aaaa</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1111bbbb</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2222cccc</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  generated\n",
       "0  0000aaaa        1.0\n",
       "1  1111bbbb        1.0\n",
       "2  2222cccc        1.0"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submition = pd.DataFrame()\n",
    "submition[\"id\"] = pre_processed_test_data[\"id\"].to_numpy()\n",
    "submition[\"generated\"] = pred.round(4)\n",
    "submition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "submition.to_csv(subPath,index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
