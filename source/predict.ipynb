{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM - Detect AI Generated Text\n",
    "# PREDICTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from gensim.models import doc2vec\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "\n",
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inferred Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features(dataset):\n",
    "    token_count=dataset[\"text\"].apply(lambda x: len(x))\n",
    "    sentence_count = []\n",
    "    punctuation_count = []\n",
    "    apostrofees_count = []\n",
    "    unk_count = []\n",
    "    for doc in dataset[\"text\"]:\n",
    "        unk = 0\n",
    "        dot = 0\n",
    "        punctuation = 0\n",
    "        apostrofees = 0\n",
    "        for token in doc:\n",
    "            if(token.endswith(\".\")):\n",
    "                dot+=1\n",
    "                punctuation+=1\n",
    "            elif(token.endswith(\",\") or token.endswith(\"?\") or token.endswith(\"!\")):\n",
    "                punctuation+=1\n",
    "            elif(token.count(\"'\")>0):\n",
    "                    apostrofees+=token.count(\"'\")\n",
    "            elif(token==\"[UNK]\"):\n",
    "                unk+=1\n",
    "        sentence_count.append(dot)\n",
    "        punctuation_count.append(punctuation)\n",
    "        apostrofees_count.append(apostrofees)\n",
    "        unk_count.append(unk)\n",
    "    df = pd.DataFrame(\n",
    "        columns=[\"token_num\",\"sent_num\",\"punct_sym\",\"apostrof_sym\",\"unk_num\"]\n",
    "    )\n",
    "    df[\"token_num\"]=token_count\n",
    "    df[\"sent_num\"]=sentence_count\n",
    "    df[\"punct_sym\"]=punctuation_count\n",
    "    df[\"apostrof_sym\"]=apostrofees_count\n",
    "    df[\"unk_num\"]=unk_count\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = pd.read_csv(\"../data/test_essays.csv\")\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained(\"../data/byte_pair_tokenizer/\")\n",
    "doc_model = doc2vec.Doc2Vec.load(\"../data/embedding_model/docModel.bin\")\n",
    "model = keras.models.load_model(\"../data/weights.h5\")\n",
    "subPath = \"../data/CNN/submission.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load tokenizer\n",
    "tokenized_test = test_dataset;\n",
    "tokenized_test[\"text\"] = test_dataset[\"text\"].apply(lambda x : tokenizer.tokenize(text=x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.579811</td>\n",
       "      <td>-0.023181</td>\n",
       "      <td>0.105455</td>\n",
       "      <td>0.964687</td>\n",
       "      <td>-1.137239</td>\n",
       "      <td>-0.284674</td>\n",
       "      <td>0.798672</td>\n",
       "      <td>1.683975</td>\n",
       "      <td>-1.452440</td>\n",
       "      <td>-1.469087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021805</td>\n",
       "      <td>-0.369931</td>\n",
       "      <td>0.773667</td>\n",
       "      <td>-0.063291</td>\n",
       "      <td>-0.743866</td>\n",
       "      <td>0.615434</td>\n",
       "      <td>0.412717</td>\n",
       "      <td>-0.246424</td>\n",
       "      <td>2.069485</td>\n",
       "      <td>-1.535682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.846651</td>\n",
       "      <td>-0.690581</td>\n",
       "      <td>-0.383330</td>\n",
       "      <td>0.381186</td>\n",
       "      <td>-0.338441</td>\n",
       "      <td>-0.331480</td>\n",
       "      <td>0.590804</td>\n",
       "      <td>0.894206</td>\n",
       "      <td>-1.246327</td>\n",
       "      <td>-0.346884</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.351556</td>\n",
       "      <td>0.513875</td>\n",
       "      <td>0.779376</td>\n",
       "      <td>0.465845</td>\n",
       "      <td>-0.495945</td>\n",
       "      <td>0.578675</td>\n",
       "      <td>0.211442</td>\n",
       "      <td>-0.000358</td>\n",
       "      <td>2.048722</td>\n",
       "      <td>-1.408140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.336258</td>\n",
       "      <td>-0.404491</td>\n",
       "      <td>-0.713487</td>\n",
       "      <td>1.189348</td>\n",
       "      <td>-0.542389</td>\n",
       "      <td>-0.520110</td>\n",
       "      <td>0.331135</td>\n",
       "      <td>0.673923</td>\n",
       "      <td>-0.803540</td>\n",
       "      <td>-0.524820</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.113739</td>\n",
       "      <td>0.120349</td>\n",
       "      <td>0.947649</td>\n",
       "      <td>0.414408</td>\n",
       "      <td>-0.583618</td>\n",
       "      <td>0.262747</td>\n",
       "      <td>-0.127890</td>\n",
       "      <td>-0.430329</td>\n",
       "      <td>1.464094</td>\n",
       "      <td>-0.798821</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0 -0.579811 -0.023181  0.105455  0.964687 -1.137239 -0.284674  0.798672   \n",
       "1 -0.846651 -0.690581 -0.383330  0.381186 -0.338441 -0.331480  0.590804   \n",
       "2 -1.336258 -0.404491 -0.713487  1.189348 -0.542389 -0.520110  0.331135   \n",
       "\n",
       "         7         8         9   ...        90        91        92        93  \\\n",
       "0  1.683975 -1.452440 -1.469087  ...  0.021805 -0.369931  0.773667 -0.063291   \n",
       "1  0.894206 -1.246327 -0.346884  ... -0.351556  0.513875  0.779376  0.465845   \n",
       "2  0.673923 -0.803540 -0.524820  ... -0.113739  0.120349  0.947649  0.414408   \n",
       "\n",
       "         94        95        96        97        98        99  \n",
       "0 -0.743866  0.615434  0.412717 -0.246424  2.069485 -1.535682  \n",
       "1 -0.495945  0.578675  0.211442 -0.000358  2.048722 -1.408140  \n",
       "2 -0.583618  0.262747 -0.127890 -0.430329  1.464094 -0.798821  \n",
       "\n",
       "[3 rows x 100 columns]"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create embeddings and normalize\n",
    "doc_model = doc2vec.Doc2Vec.load(\"../data/lexp/embedding_model/docModel.bin\")\n",
    "arr = [doc_model.infer_vector(doc) for doc in tokenized_test[\"text\"]]\n",
    "embeddings_dataset = pd.DataFrame(np.reshape(arr,(len(arr), 100)))\n",
    "norma = np.linalg.norm(embeddings_dataset, axis=1)\n",
    "norma\n",
    "norm_embeddings_dataset = pd.DataFrame(np.apply_along_axis(lambda x: x / np.linalg.norm(x), axis=1, arr=embeddings_dataset))\n",
    "norm_embeddings_dataset[\"normalized_norm\"] = (norma - norma.min()) / (norma.max() - norma.min())\n",
    "norm_embeddings_dataset\n",
    "# Calcular características adicionales con la función 'features' (no proporcionada en tu código)\n",
    "feature_data = features(tokenized_test)\n",
    "feature_data\n",
    "# Normalizar las características adicionales\n",
    "feature_data_arr = pd.DataFrame(np.reshape(feature_data,(len(feature_data), len(feature_data.columns))))\n",
    "norm_feature_data = pd.DataFrame(np.apply_along_axis(lambda x: x / np.linalg.norm(x) if x.max()>0 else 0,axis=0,arr=feature_data_arr),columns=feature_data.columns)\n",
    "norm_feature_data\n",
    "test = pd.concat([tokenized_test[[\"id\",\"prompt_id\"]].reset_index(drop=True),norm_feature_data, norm_embeddings_dataset], axis=1)\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test.drop([\"id\"],axis=1)\n",
    "pred = model.predict(x=X_test)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>generated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000aaaa</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1111bbbb</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2222cccc</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  generated\n",
       "0  0000aaaa        1.0\n",
       "1  1111bbbb        1.0\n",
       "2  2222cccc        1.0"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submition = pd.DataFrame()\n",
    "submition[\"id\"] = test[\"id\"].to_numpy()\n",
    "submition[\"generated\"] = pred.round(4)\n",
    "submition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "submition.to_csv(subPath,index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
